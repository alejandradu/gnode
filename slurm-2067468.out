2024-04-07 14:33:44,569	INFO worker.py:1724 -- Started a local Ray instance.
2024-04-07 14:33:57,446	INFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
2024-04-07 14:33:57,447	INFO tune.py:592 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949
2024-04-07 14:33:57,468	WARNING tune.py:916 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.
[36m(train pid=805865)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=805865)[0m The version_base parameter is not specified.
[36m(train pid=805865)[0m Please specify a compatability version level, or None.
[36m(train pid=805865)[0m Will assume defaults for version 1.1
[36m(train pid=805865)[0m   with hydra.initialize(
[36m(train pid=805865)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=805865)[0m The version_base parameter is not specified.
[36m(train pid=805865)[0m Please specify a compatability version level, or None.
[36m(train pid=805865)[0m Will assume defaults for version 1.1
[36m(train pid=805865)[0m   with hydra.initialize(
[36m(train pid=805865)[0m [rank: 0] Seed set to 0
[36m(train pid=805865)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=805865)[0m GPU available: True (cuda), used: True
[36m(train pid=805865)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=805865)[0m IPU available: False, using: 0 IPUs
[36m(train pid=805865)[0m HPU available: False, using: 0 HPUs
[36m(train pid=805865)[0m You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[36m(train pid=805865)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=805865)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-07_14-33-57/0_latent_size=128,batch_size=256,n_samples=500,num_workers=1,seed=0,learning_rate=0.0001,weight_decay=0.0010,log_every_n_steps=2,max_epochs=300 exists and is not empty.
[36m(train pid=805865)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=805865)[0m 
[36m(train pid=805865)[0m   | Name  | Type    | Params
[36m(train pid=805865)[0m ----------------------------------
[36m(train pid=805865)[0m 0 | model | GRU_RNN | 50.4 K
[36m(train pid=805865)[0m ----------------------------------
[36m(train pid=805865)[0m 50.4 K    Trainable params
[36m(train pid=805865)[0m 0         Non-trainable params
[36m(train pid=805865)[0m 50.4 K    Total params
[36m(train pid=805865)[0m 0.202     Total estimated model params size (MB)
[36m(train pid=805865)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=805865)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=805865)[0m   warnings.warn(_create_warning_msg(
[36m(train pid=805865)[0m `Trainer.fit` stopped: `max_epochs=300` reached.
[36m(train pid=932740)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=932740)[0m The version_base parameter is not specified.
[36m(train pid=932740)[0m Please specify a compatability version level, or None.
[36m(train pid=932740)[0m Will assume defaults for version 1.1
[36m(train pid=932740)[0m   with hydra.initialize(
[36m(train pid=932740)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=932740)[0m The version_base parameter is not specified.
[36m(train pid=932740)[0m Please specify a compatability version level, or None.
[36m(train pid=932740)[0m Will assume defaults for version 1.1
[36m(train pid=932740)[0m   with hydra.initialize(
[36m(train pid=932740)[0m [rank: 0] Seed set to 0
[36m(train pid=932740)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=932740)[0m GPU available: True (cuda), used: True
[36m(train pid=932740)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=932740)[0m IPU available: False, using: 0 IPUs
[36m(train pid=932740)[0m HPU available: False, using: 0 HPUs
[36m(train pid=932740)[0m You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[36m(train pid=932740)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=932740)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-07_14-33-57/1_latent_size=128,batch_size=256,n_samples=500,num_workers=1,seed=0,learning_rate=0.0000,weight_decay=0.0010,log_every_n_steps=2,max_epochs=300 exists and is not empty.
[36m(train pid=932740)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=932740)[0m 
[36m(train pid=932740)[0m   | Name  | Type    | Params
[36m(train pid=932740)[0m ----------------------------------
[36m(train pid=932740)[0m 0 | model | GRU_RNN | 50.4 K
[36m(train pid=932740)[0m ----------------------------------
[36m(train pid=932740)[0m 50.4 K    Trainable params
[36m(train pid=932740)[0m 0         Non-trainable params
[36m(train pid=932740)[0m 50.4 K    Total params
[36m(train pid=932740)[0m 0.202     Total estimated model params size (MB)
[36m(train pid=932740)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=932740)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=932740)[0m   warnings.warn(_create_warning_msg(
[36m(train pid=932740)[0m `Trainer.fit` stopped: `max_epochs=300` reached.
[36m(train pid=1056727)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=1056727)[0m The version_base parameter is not specified.
[36m(train pid=1056727)[0m Please specify a compatability version level, or None.
[36m(train pid=1056727)[0m Will assume defaults for version 1.1
[36m(train pid=1056727)[0m   with hydra.initialize(
[36m(train pid=1056727)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=1056727)[0m The version_base parameter is not specified.
[36m(train pid=1056727)[0m Please specify a compatability version level, or None.
[36m(train pid=1056727)[0m Will assume defaults for version 1.1
[36m(train pid=1056727)[0m   with hydra.initialize(
[36m(train pid=1056727)[0m [rank: 0] Seed set to 0
[36m(train pid=1056727)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=1056727)[0m GPU available: True (cuda), used: True
[36m(train pid=1056727)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=1056727)[0m IPU available: False, using: 0 IPUs
[36m(train pid=1056727)[0m HPU available: False, using: 0 HPUs
[36m(train pid=1056727)[0m You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[36m(train pid=1056727)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=1056727)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-07_14-33-57/2_latent_size=128,batch_size=256,n_samples=500,num_workers=1,seed=0,learning_rate=0.0000,weight_decay=0.0010,log_every_n_steps=2,max_epochs=300 exists and is not empty.
[36m(train pid=1056727)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=1056727)[0m 
[36m(train pid=1056727)[0m   | Name  | Type    | Params
[36m(train pid=1056727)[0m ----------------------------------
[36m(train pid=1056727)[0m 0 | model | GRU_RNN | 50.4 K
[36m(train pid=1056727)[0m ----------------------------------
[36m(train pid=1056727)[0m 50.4 K    Trainable params
[36m(train pid=1056727)[0m 0         Non-trainable params
[36m(train pid=1056727)[0m 50.4 K    Total params
[36m(train pid=1056727)[0m 0.202     Total estimated model params size (MB)
[36m(train pid=1056727)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=1056727)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=1056727)[0m   warnings.warn(_create_warning_msg(
[36m(train pid=1056727)[0m `Trainer.fit` stopped: `max_epochs=300` reached.
[36m(train pid=1180917)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=1180917)[0m The version_base parameter is not specified.
[36m(train pid=1180917)[0m Please specify a compatability version level, or None.
[36m(train pid=1180917)[0m Will assume defaults for version 1.1
[36m(train pid=1180917)[0m   with hydra.initialize(
[36m(train pid=1180917)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=1180917)[0m The version_base parameter is not specified.
[36m(train pid=1180917)[0m Please specify a compatability version level, or None.
[36m(train pid=1180917)[0m Will assume defaults for version 1.1
[36m(train pid=1180917)[0m   with hydra.initialize(
[36m(train pid=1180917)[0m [rank: 0] Seed set to 0
[36m(train pid=1180917)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=1180917)[0m GPU available: True (cuda), used: True
[36m(train pid=1180917)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=1180917)[0m IPU available: False, using: 0 IPUs
[36m(train pid=1180917)[0m HPU available: False, using: 0 HPUs
[36m(train pid=1180917)[0m You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[36m(train pid=1180917)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=1180917)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-07_14-33-57/3_latent_size=128,batch_size=512,n_samples=500,num_workers=1,seed=0,learning_rate=0.0001,weight_decay=0.0000,log_every_n_steps=2,max_epochs=300 exists and is not empty.
[36m(train pid=1180917)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=1180917)[0m 
[36m(train pid=1180917)[0m   | Name  | Type    | Params
[36m(train pid=1180917)[0m ----------------------------------
[36m(train pid=1180917)[0m 0 | model | GRU_RNN | 50.4 K
[36m(train pid=1180917)[0m ----------------------------------
[36m(train pid=1180917)[0m 50.4 K    Trainable params
[36m(train pid=1180917)[0m 0         Non-trainable params
[36m(train pid=1180917)[0m 50.4 K    Total params
[36m(train pid=1180917)[0m 0.202     Total estimated model params size (MB)
[36m(train pid=1180917)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=1180917)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=1180917)[0m   warnings.warn(_create_warning_msg(
╭──────────────────────────────────────────────────────────────╮
│ Configuration for experiment     train_2024-04-07_14-33-57   │
├──────────────────────────────────────────────────────────────┤
│ Search algorithm                 BasicVariantGenerator       │
│ Scheduler                        FIFOScheduler               │
│ Number of trials                 6                           │
╰──────────────────────────────────────────────────────────────╯

View detailed results here: /scratch/network/ad2002/content/runs/task-trained/20240407_GRU_OBS_300epoch/train_2024-04-07_14-33-57
To visualize your results with TensorBoard, run: `tensorboard --logdir /home/ad2002/ray_results/train_2024-04-07_14-33-57`

Trial status: 6 PENDING
Current time: 2024-04-07 14:33:57. Total running time: 0s
Logical resource usage: 0/48 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0 │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0 │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0 │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0 │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_5bb3b_00000 started with configuration:
╭───────────────────────────────────────────╮
│ Trial train_5bb3b_00000 config            │
├───────────────────────────────────────────┤
│ model/latent_size                     128 │
│ params/batch_size                     256 │
│ params/n_samples                      500 │
│ params/num_workers                      1 │
│ params/seed                             0 │
│ task_wrapper/learning_rate         0.0001 │
│ task_wrapper/weight_decay           0.001 │
│ trainer/log_every_n_steps               2 │
│ trainer/max_epochs                    300 │
╰───────────────────────────────────────────╯

Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:34:27. Total running time: 30s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.8796714544296265 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0        3            24.7342   0.879671 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:34:57. Total running time: 1min 0s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.878409206867218 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0        9            57.1418   0.878409 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:35:27. Total running time: 1min 30s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.8774498701095581 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       14            83.8945   0.87745 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                       │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                       │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                       │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                       │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:35:57. Total running time: 2min 0s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.8762815594673157 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       20            116.254   0.876282 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:36:27. Total running time: 2min 30s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.8752330541610718 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       25            143.056   0.875233 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:36:57. Total running time: 3min 0s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.8738129138946533 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       31            175.385   0.873813 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:37:27. Total running time: 3min 30s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.8725844025611877 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       37            207.439   0.872584 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:37:58. Total running time: 4min 0s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.8714438676834106 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       42            234.401   0.871444 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:38:28. Total running time: 4min 30s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.8693149089813232 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       48            266.425   0.869315 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:38:58. Total running time: 5min 0s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.867481529712677 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       53            293.043   0.867482 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:39:28. Total running time: 5min 30s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.8643942475318909 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       59            325.019   0.864394 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:39:58. Total running time: 6min 0s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.8580485582351685 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       65            357.012   0.858049 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:40:28. Total running time: 6min 30s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.8441078662872314 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       70            383.664   0.844108 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:40:58. Total running time: 7min 0s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=1.0985850095748901 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       76             415.58   1.09859 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                       │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                       │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                       │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                       │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:41:28. Total running time: 7min 30s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.43918174505233765 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       82            447.632   0.439182 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:41:58. Total running time: 8min 0s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.3841300308704376 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       87             474.33   0.38413 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                       │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                       │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                       │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                       │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:42:28. Total running time: 8min 30s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.39898985624313354 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       93             506.67   0.39899 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                       │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                       │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                       │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                       │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:42:58. Total running time: 9min 1s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.38648146390914917 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0       98            533.281   0.386481 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:43:28. Total running time: 9min 31s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37956276535987854 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      104            565.198   0.379563 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:43:58. Total running time: 10min 1s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.386561781167984 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      110             597.72   0.386562 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:44:28. Total running time: 10min 31s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.4143819808959961 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      115            624.578   0.414382 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:44:58. Total running time: 11min 1s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.38607528805732727 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      121            656.603   0.386075 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:45:28. Total running time: 11min 31s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.38186725974082947 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      126            683.226   0.381867 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:45:58. Total running time: 12min 1s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.38845282793045044 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      132            715.139   0.388453 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:46:28. Total running time: 12min 31s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.3932589590549469 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      138            747.018   0.393259 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:46:58. Total running time: 13min 1s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.4085296392440796 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      143            773.657   0.40853 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                       │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                       │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                       │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                       │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:47:28. Total running time: 13min 31s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.3801945745944977 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      149            805.757   0.380195 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:47:58. Total running time: 14min 1s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.3908679187297821 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      155            837.683   0.390868 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:48:28. Total running time: 14min 31s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37456318736076355 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      160            864.263   0.374563 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:48:58. Total running time: 15min 1s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.39360418915748596 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      166            896.101   0.393604 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:49:29. Total running time: 15min 31s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37116092443466187 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      171            923.147   0.371161 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:49:59. Total running time: 16min 1s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.3713288903236389 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      177             955.04   0.371329 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:50:29. Total running time: 16min 31s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.36952054500579834 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      183            986.935   0.369521 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:50:59. Total running time: 17min 1s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37169724702835083 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      188            1013.51   0.371697 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:51:29. Total running time: 17min 31s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.3850850760936737 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      194            1045.48   0.385085 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:51:59. Total running time: 18min 1s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.36837396025657654 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      200            1077.45   0.368374 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:52:29. Total running time: 18min 31s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.38030219078063965 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      205            1104.12   0.380302 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:52:59. Total running time: 19min 1s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.3750338852405548 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      211            1135.97   0.375034 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:53:29. Total running time: 19min 31s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.378632515668869 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      217            1167.86   0.378633 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:53:59. Total running time: 20min 1s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.38115429878234863 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      222            1194.93   0.381154 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:54:29. Total running time: 20min 31s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.370486855506897 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      228            1226.78   0.370487 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:54:59. Total running time: 21min 2s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.3682352900505066 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      233            1253.31   0.368235 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:55:29. Total running time: 21min 32s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37304648756980896 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      239            1285.18   0.373046 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:55:59. Total running time: 22min 2s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.374520480632782 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      245            1317.02   0.37452 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                       │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                       │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                       │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                       │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:56:29. Total running time: 22min 32s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.36698684096336365 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      250            1343.62   0.366987 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:56:59. Total running time: 23min 2s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.36920422315597534 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      256            1375.56   0.369204 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:57:29. Total running time: 23min 32s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37069010734558105 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      262            1407.41   0.37069 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                       │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                       │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                       │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                       │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:57:59. Total running time: 24min 2s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37029603123664856 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      267            1433.92   0.370296 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:58:29. Total running time: 24min 32s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.36948272585868835 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      273            1465.68   0.369483 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:58:59. Total running time: 25min 2s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.3704656958580017 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      279            1497.46   0.370466 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:59:29. Total running time: 25min 32s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.38860881328582764 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      284            1524.08   0.388609 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 14:59:59. Total running time: 26min 2s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37254151701927185 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      290            1556.09   0.372542 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 5 PENDING
Current time: 2024-04-07 15:00:30. Total running time: 26min 32s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37184733152389526 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   RUNNING                     300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      296            1587.93   0.371847 │
│ train_5bb3b_00001   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00002   PENDING                     300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                     300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                     300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_5bb3b_00000 completed after 300 iterations at 2024-04-07 15:00:50. Total running time: 26min 52s
╭────────────────────────────────────────────╮
│ Trial train_5bb3b_00000 result             │
├────────────────────────────────────────────┤
│ checkpoint_dir_name                        │
│ time_this_iter_s                    5.3396 │
│ time_total_s                       1609.28 │
│ training_iteration                     300 │
│ loss                               0.37593 │
╰────────────────────────────────────────────╯

Trial train_5bb3b_00001 started with configuration:
╭──────────────────────────────────────────╮
│ Trial train_5bb3b_00001 config           │
├──────────────────────────────────────────┤
│ model/latent_size                    128 │
│ params/batch_size                    256 │
│ params/n_samples                     500 │
│ params/num_workers                     1 │
│ params/seed                            0 │
│ task_wrapper/learning_rate         1e-06 │
│ task_wrapper/weight_decay          0.001 │
│ trainer/log_every_n_steps              2 │
│ trainer/max_epochs                   300 │
╰──────────────────────────────────────────╯

Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:01:00. Total running time: 27min 2s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0                                        │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:01:30. Total running time: 27min 32s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0        5            34.9493   0.880387 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:02:00. Total running time: 28min 2s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       10            61.5713   0.880373 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:02:30. Total running time: 28min 32s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       16            93.5726   0.880356 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:03:00. Total running time: 29min 2s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       22            125.605   0.88034  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:03:30. Total running time: 29min 32s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       27            152.245   0.880326 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:04:00. Total running time: 30min 2s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       33            185.273   0.880312 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:04:30. Total running time: 30min 32s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       38             211.86   0.880299 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:05:00. Total running time: 31min 2s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       44            243.762   0.880283 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:05:30. Total running time: 31min 32s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       50            275.703   0.88027  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:06:00. Total running time: 32min 2s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       55            302.397   0.880257 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:06:30. Total running time: 32min 32s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       61            334.416   0.880243 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:07:00. Total running time: 33min 3s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       67            366.551   0.880229 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:07:30. Total running time: 33min 33s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       72            393.398   0.880218 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:08:00. Total running time: 34min 3s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       78            425.463   0.880204 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:08:30. Total running time: 34min 33s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       83            452.085   0.880193 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:09:00. Total running time: 35min 3s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       89             484.8    0.880179 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:09:30. Total running time: 35min 33s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0       95            516.725   0.880165 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:10:00. Total running time: 36min 3s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      100            544.012   0.880153 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:10:30. Total running time: 36min 33s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      106            575.982   0.880138 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:11:00. Total running time: 37min 3s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      111            602.678   0.880126 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:11:30. Total running time: 37min 33s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      117            634.717   0.880113 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:12:00. Total running time: 38min 3s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      123            666.818   0.8801   │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:12:30. Total running time: 38min 33s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      128            693.499   0.880088 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:13:00. Total running time: 39min 3s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      134             725.56   0.880074 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:13:31. Total running time: 39min 33s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      139            752.315   0.880062 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:14:01. Total running time: 40min 3s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      145            784.931   0.880048 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:14:31. Total running time: 40min 33s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      151            816.895   0.880034 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:15:01. Total running time: 41min 3s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      156            844.844   0.880023 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:15:31. Total running time: 41min 33s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      162            876.831   0.880009 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:16:01. Total running time: 42min 3s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      167            903.515   0.879998 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:16:31. Total running time: 42min 33s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      173            935.441   0.879985 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:17:01. Total running time: 43min 3s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      178            962.204   0.879974 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:17:31. Total running time: 43min 34s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      184            994.291   0.879961 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:18:01. Total running time: 44min 4s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      190            1026.58   0.879947 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:18:31. Total running time: 44min 34s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      195            1053.86   0.879936 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:19:01. Total running time: 45min 4s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      201            1086.17   0.879923 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:19:31. Total running time: 45min 34s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      206            1112.91   0.879912 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:20:01. Total running time: 46min 4s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      212            1145.24   0.879897 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:20:31. Total running time: 46min 34s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      218            1177.46   0.879884 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:21:01. Total running time: 47min 4s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      223            1204.15   0.879873 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:21:31. Total running time: 47min 34s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      229            1236.12   0.879859 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:22:01. Total running time: 48min 4s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      234            1262.82   0.879848 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:22:31. Total running time: 48min 34s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      240            1294.77   0.879834 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:23:02. Total running time: 49min 4s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      246            1326.82   0.879822 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:23:32. Total running time: 49min 34s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      251            1353.45   0.879811 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:24:02. Total running time: 50min 4s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      257            1385.93   0.879797 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:24:32. Total running time: 50min 34s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      262            1412.62   0.879786 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:25:02. Total running time: 51min 4s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      268            1444.63   0.879773 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:25:32. Total running time: 51min 34s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      274            1476.54   0.87976  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:26:02. Total running time: 52min 4s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      279            1503.19   0.879749 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:26:32. Total running time: 52min 34s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      285            1535.14   0.879736 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:27:02. Total running time: 53min 4s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      291            1567.08   0.879723 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-07 15:27:32. Total running time: 53min 34s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00001   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      296            1593.69   0.879712 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00002   PENDING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_5bb3b_00001 completed after 300 iterations at 2024-04-07 15:27:49. Total running time: 53min 52s
╭────────────────────────────────────────────╮
│ Trial train_5bb3b_00001 result             │
├────────────────────────────────────────────┤
│ checkpoint_dir_name                        │
│ time_this_iter_s                    5.3474 │
│ time_total_s                       1615.04 │
│ training_iteration                     300 │
│ loss                                0.8797 │
╰────────────────────────────────────────────╯

Trial train_5bb3b_00002 started with configuration:
╭──────────────────────────────────────────╮
│ Trial train_5bb3b_00002 config           │
├──────────────────────────────────────────┤
│ model/latent_size                    128 │
│ params/batch_size                    256 │
│ params/n_samples                     500 │
│ params/num_workers                     1 │
│ params/seed                            0 │
│ task_wrapper/learning_rate         1e-07 │
│ task_wrapper/weight_decay          0.001 │
│ trainer/log_every_n_steps              2 │
│ trainer/max_epochs                   300 │
╰──────────────────────────────────────────╯

Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:28:02. Total running time: 54min 5s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0                                        │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:28:32. Total running time: 54min 35s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0        5            35.1022   0.880399 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300          1615.04     0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:29:02. Total running time: 55min 5s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       11            67.1595   0.880397 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300          1615.04     0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:29:32. Total running time: 55min 35s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       17            99.2216   0.880396 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300          1615.04     0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:30:02. Total running time: 56min 5s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       22            125.854   0.880394 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:30:32. Total running time: 56min 35s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       28            157.877   0.880392 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:31:02. Total running time: 57min 5s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       33            184.734   0.880391 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:31:32. Total running time: 57min 35s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       39            216.794   0.88039  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:32:02. Total running time: 58min 5s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       45            248.897   0.880388 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:32:32. Total running time: 58min 35s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       50            275.592   0.880387 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:33:03. Total running time: 59min 5s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       56            307.727   0.880385 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:33:33. Total running time: 59min 35s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       62            339.787   0.880384 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:34:03. Total running time: 1hr 0min 5s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       67            367.054   0.880383 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:34:33. Total running time: 1hr 0min 35s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       73            399.094   0.880381 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:35:03. Total running time: 1hr 1min 5s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       78            425.867   0.88038  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:35:33. Total running time: 1hr 1min 35s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       84            457.999   0.880379 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:36:03. Total running time: 1hr 2min 5s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       90             490.18   0.880377 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:36:33. Total running time: 1hr 2min 36s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0       95            516.922   0.880376 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:37:03. Total running time: 1hr 3min 6s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      101            549.084   0.880374 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:37:33. Total running time: 1hr 3min 36s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      106            575.911   0.880373 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:38:03. Total running time: 1hr 4min 6s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      112            608.071   0.880371 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:38:33. Total running time: 1hr 4min 36s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      118            640.184   0.88037  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:39:03. Total running time: 1hr 5min 6s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      123            666.982   0.880369 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:39:33. Total running time: 1hr 5min 36s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      129             699.31   0.880367 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:40:03. Total running time: 1hr 6min 6s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      134            726.457   0.880366 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:40:33. Total running time: 1hr 6min 36s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      140            758.734   0.880365 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:41:04. Total running time: 1hr 7min 6s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      145            785.683   0.880364 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:41:34. Total running time: 1hr 7min 36s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      151            817.975   0.880362 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:42:04. Total running time: 1hr 8min 6s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      157            850.282   0.880361 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:42:34. Total running time: 1hr 8min 36s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      162            877.111   0.880359 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:43:04. Total running time: 1hr 9min 6s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      168             909.38   0.880358 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:43:34. Total running time: 1hr 9min 36s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      173            936.127   0.880357 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:44:04. Total running time: 1hr 10min 6s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      179            968.839   0.880355 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:44:34. Total running time: 1hr 10min 36s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      184            995.683   0.880354 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:45:04. Total running time: 1hr 11min 7s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      190            1027.84   0.880353 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:45:34. Total running time: 1hr 11min 37s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      196            1060      0.880351 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:46:04. Total running time: 1hr 12min 7s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      201            1086.76   0.88035  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:46:34. Total running time: 1hr 12min 37s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      207            1118.78   0.880349 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:47:04. Total running time: 1hr 13min 7s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      213            1150.82   0.880347 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:47:34. Total running time: 1hr 13min 37s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      218            1177.57   0.880346 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:48:04. Total running time: 1hr 14min 7s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      224            1209.61   0.880344 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:48:34. Total running time: 1hr 14min 37s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      229            1236.24   0.880343 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:49:04. Total running time: 1hr 15min 7s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      235            1267.79   0.880341 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:49:34. Total running time: 1hr 15min 37s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      241            1300.13   0.88034  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:50:05. Total running time: 1hr 16min 7s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      246            1326.75   0.880339 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:50:35. Total running time: 1hr 16min 37s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      252            1358.61   0.880337 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:51:05. Total running time: 1hr 17min 7s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      258            1390.56   0.880336 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:51:35. Total running time: 1hr 17min 37s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      263            1417.17   0.880334 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:52:05. Total running time: 1hr 18min 7s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      269            1449.11   0.880333 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:52:35. Total running time: 1hr 18min 37s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      275            1481.08   0.880332 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:53:05. Total running time: 1hr 19min 7s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      280            1507.67   0.88033  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:53:35. Total running time: 1hr 19min 37s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      286            1539.64   0.880329 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:54:05. Total running time: 1hr 20min 8s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      291            1566.76   0.880328 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-07 15:54:35. Total running time: 1hr 20min 38s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00002   RUNNING                       300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      297            1598.55   0.880326 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00003   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0                                        │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_5bb3b_00002 completed after 300 iterations at 2024-04-07 15:54:48. Total running time: 1hr 20min 50s
╭────────────────────────────────────────────╮
│ Trial train_5bb3b_00002 result             │
├────────────────────────────────────────────┤
│ checkpoint_dir_name                        │
│ time_this_iter_s                   5.32498 │
│ time_total_s                       1614.53 │
│ training_iteration                     300 │
│ loss                               0.88033 │
╰────────────────────────────────────────────╯

Trial train_5bb3b_00003 started with configuration:
╭───────────────────────────────────────────╮
│ Trial train_5bb3b_00003 config            │
├───────────────────────────────────────────┤
│ model/latent_size                     128 │
│ params/batch_size                     512 │
│ params/n_samples                      500 │
│ params/num_workers                      1 │
│ params/seed                             0 │
│ task_wrapper/learning_rate         0.0001 │
│ task_wrapper/weight_decay           1e-07 │
│ trainer/log_every_n_steps               2 │
│ trainer/max_epochs                    300 │
╰───────────────────────────────────────────╯

Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 15:55:05. Total running time: 1hr 21min 8s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0        1            13.2594   0.880099 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300          1615.04     0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300          1614.53     0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 15:55:35. Total running time: 1hr 21min 38s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0        6             39.853   0.8789   │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 15:56:05. Total running time: 1hr 22min 8s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       12            71.6784   0.877561 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300          1615.04     0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300          1614.53     0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 15:56:35. Total running time: 1hr 22min 38s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       18             103.67   0.876174 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 15:57:05. Total running time: 1hr 23min 8s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       23            130.321   0.874912 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 15:57:35. Total running time: 1hr 23min 38s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       29             162.47   0.873156 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 15:58:05. Total running time: 1hr 24min 8s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       35            194.719   0.871266 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 15:58:36. Total running time: 1hr 24min 38s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       40            221.489   0.869618 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 15:59:06. Total running time: 1hr 25min 8s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       46            253.478   0.865534 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 15:59:36. Total running time: 1hr 25min 38s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       51            280.186   0.860294 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:00:06. Total running time: 1hr 26min 8s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       57            312.088   0.842017 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:00:36. Total running time: 1hr 26min 38s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       63            343.832   0.78211  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:01:06. Total running time: 1hr 27min 8s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       68            370.485   0.428335 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:01:36. Total running time: 1hr 27min 39s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       74            402.396   0.392054 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:02:06. Total running time: 1hr 28min 9s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       80            434.367   0.389277 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:02:36. Total running time: 1hr 28min 39s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       85            461.012   0.381107 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:03:06. Total running time: 1hr 29min 9s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       91            493.462   0.3763   │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:03:36. Total running time: 1hr 29min 39s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3758322596549988 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0       96            520.391   0.375832 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:04:06. Total running time: 1hr 30min 9s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.366983026266098 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      102            552.455   0.366983 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:04:36. Total running time: 1hr 30min 39s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      108            583.789   0.415321 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:05:06. Total running time: 1hr 31min 9s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3752198815345764 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      114            615.082   0.37522  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:05:36. Total running time: 1hr 31min 39s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      119            641.182   0.382156 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:06:07. Total running time: 1hr 32min 9s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3606833517551422 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      125             672.53   0.360683 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:06:37. Total running time: 1hr 32min 39s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3637368679046631 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      131            703.893   0.363737 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:07:07. Total running time: 1hr 33min 9s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3610212206840515 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      137            735.272   0.361021 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:07:37. Total running time: 1hr 33min 39s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.35856959223747253 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      142             761.36   0.35857  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:08:07. Total running time: 1hr 34min 9s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      148            792.607   0.386892 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:08:37. Total running time: 1hr 34min 39s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      154            823.949   0.380567 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:09:07. Total running time: 1hr 35min 9s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      160            855.519   0.378598 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:09:37. Total running time: 1hr 35min 39s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3643434941768646 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      165            881.659   0.364343 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:10:07. Total running time: 1hr 36min 10s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3684292137622833 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      171            913.002   0.368429 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:10:37. Total running time: 1hr 36min 40s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.36074554920196533 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      177            944.326   0.360746 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:11:07. Total running time: 1hr 37min 10s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00000 with loss=0.37592679262161255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 0.001, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 256, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      183            975.613   0.383645 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:11:37. Total running time: 1hr 37min 40s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.35729697346687317 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      188            1001.78   0.357297 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:12:07. Total running time: 1hr 38min 10s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3545316755771637 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      194            1033.08   0.354532 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:12:37. Total running time: 1hr 38min 40s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.358083575963974 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      200            1064.38   0.358084 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:13:07. Total running time: 1hr 39min 10s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3562394976615906 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      206            1095.74   0.356239 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:13:37. Total running time: 1hr 39min 40s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3502046465873718 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      211            1121.94   0.350205 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:14:07. Total running time: 1hr 40min 10s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.35156935453414917 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      217            1153.85   0.351569 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:14:37. Total running time: 1hr 40min 40s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.34964674711227417 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      223            1185.15   0.349647 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:15:07. Total running time: 1hr 41min 10s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.35118672251701355 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      228            1211.3    0.351187 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:15:37. Total running time: 1hr 41min 40s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3688325583934784 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      234            1242.64   0.368833 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:16:08. Total running time: 1hr 42min 10s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3482782244682312 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      240            1274.04   0.348278 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:16:38. Total running time: 1hr 42min 40s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3520974814891815 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      246            1305.38   0.352097 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:17:08. Total running time: 1hr 43min 10s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3503994345664978 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      251            1331.46   0.350399 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:17:38. Total running time: 1hr 43min 40s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3433070480823517 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      257            1362.83   0.343307 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:18:08. Total running time: 1hr 44min 10s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.34352177381515503 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      263            1394.27   0.343522 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:18:38. Total running time: 1hr 44min 40s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3611615002155304 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      269            1425.68   0.361162 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:19:08. Total running time: 1hr 45min 10s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.34311407804489136 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      274            1451.69   0.343114 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:19:38. Total running time: 1hr 45min 40s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3461213707923889 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
[36m(train pid=1180917)[0m `Trainer.fit` stopped: `max_epochs=300` reached.
[36m(train pid=1304643)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=1304643)[0m The version_base parameter is not specified.
[36m(train pid=1304643)[0m Please specify a compatability version level, or None.
[36m(train pid=1304643)[0m Will assume defaults for version 1.1
[36m(train pid=1304643)[0m   with hydra.initialize(
[36m(train pid=1304643)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=1304643)[0m The version_base parameter is not specified.
[36m(train pid=1304643)[0m Please specify a compatability version level, or None.
[36m(train pid=1304643)[0m Will assume defaults for version 1.1
[36m(train pid=1304643)[0m   with hydra.initialize(
[36m(train pid=1304643)[0m [rank: 0] Seed set to 0
[36m(train pid=1304643)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=1304643)[0m GPU available: True (cuda), used: True
[36m(train pid=1304643)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=1304643)[0m IPU available: False, using: 0 IPUs
[36m(train pid=1304643)[0m HPU available: False, using: 0 HPUs
[36m(train pid=1304643)[0m You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[36m(train pid=1304643)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=1304643)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-07_14-33-57/4_latent_size=128,batch_size=512,n_samples=500,num_workers=1,seed=0,learning_rate=0.0000,weight_decay=0.0000,log_every_n_steps=2,max_epochs=300 exists and is not empty.
[36m(train pid=1304643)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=1304643)[0m 
[36m(train pid=1304643)[0m   | Name  | Type    | Params
[36m(train pid=1304643)[0m ----------------------------------
[36m(train pid=1304643)[0m 0 | model | GRU_RNN | 50.4 K
[36m(train pid=1304643)[0m ----------------------------------
[36m(train pid=1304643)[0m 50.4 K    Trainable params
[36m(train pid=1304643)[0m 0         Non-trainable params
[36m(train pid=1304643)[0m 50.4 K    Total params
[36m(train pid=1304643)[0m 0.202     Total estimated model params size (MB)
[36m(train pid=1304643)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=1304643)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=1304643)[0m   warnings.warn(_create_warning_msg(
[36m(train pid=1304643)[0m `Trainer.fit` stopped: `max_epochs=300` reached.
[36m(train pid=1426258)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=1426258)[0m The version_base parameter is not specified.
[36m(train pid=1426258)[0m Please specify a compatability version level, or None.
[36m(train pid=1426258)[0m Will assume defaults for version 1.1
[36m(train pid=1426258)[0m   with hydra.initialize(
[36m(train pid=1426258)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=1426258)[0m The version_base parameter is not specified.
[36m(train pid=1426258)[0m Please specify a compatability version level, or None.
[36m(train pid=1426258)[0m Will assume defaults for version 1.1
[36m(train pid=1426258)[0m   with hydra.initialize(
[36m(train pid=1426258)[0m [rank: 0] Seed set to 0
[36m(train pid=1426258)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=1426258)[0m GPU available: True (cuda), used: True
[36m(train pid=1426258)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=1426258)[0m IPU available: False, using: 0 IPUs
[36m(train pid=1426258)[0m HPU available: False, using: 0 HPUs
[36m(train pid=1426258)[0m You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[36m(train pid=1426258)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=1426258)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-07_14-33-57/5_latent_size=128,batch_size=256,n_samples=500,num_workers=1,seed=0,learning_rate=0.0000,weight_decay=0.0000,log_every_n_steps=2,max_epochs=300 exists and is not empty.
[36m(train pid=1426258)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=1426258)[0m 
[36m(train pid=1426258)[0m   | Name  | Type    | Params
[36m(train pid=1426258)[0m ----------------------------------
[36m(train pid=1426258)[0m 0 | model | GRU_RNN | 50.4 K
[36m(train pid=1426258)[0m ----------------------------------
[36m(train pid=1426258)[0m 50.4 K    Trainable params
[36m(train pid=1426258)[0m 0         Non-trainable params
[36m(train pid=1426258)[0m 50.4 K    Total params
[36m(train pid=1426258)[0m 0.202     Total estimated model params size (MB)
[36m(train pid=1426258)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=1426258)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=1426258)[0m   warnings.warn(_create_warning_msg(
2024-04-07 16:59:44,356	WARNING syncer.py:405 -- Last sync command failed with the following error:
Traceback (most recent call last):
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/train/_internal/syncer.py", line 403, in _launch_sync_process
    self.wait()
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/train/_internal/syncer.py", line 473, in wait
    raise e
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/train/_internal/syncer.py", line 471, in wait
    self._sync_process.wait(timeout=self.sync_timeout)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/train/_internal/syncer.py", line 173, in wait
    raise exception
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/train/_internal/syncer.py", line 136, in entrypoint
    result = self._fn(*args, **kwargs)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/train/_internal/storage.py", line 215, in _upload_to_fs_path
    _upload_to_uri_with_exclude_fsspec(
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/train/_internal/storage.py", line 228, in _upload_to_uri_with_exclude_fsspec
    _pyarrow_fs_copy_files(
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/train/_internal/storage.py", line 110, in _pyarrow_fs_copy_files
    return pyarrow.fs.copy_files(
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pyarrow/fs.py", line 272, in copy_files
    _copy_files_selector(source_fs, source_sel,
  File "pyarrow/_fs.pyx", line 1627, in pyarrow._fs._copy_files_selector
  File "pyarrow/error.pxi", line 88, in pyarrow.lib.check_status
  File "pyarrow/_fs.pyx", line 1554, in pyarrow._fs._cb_open_input_stream
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pyarrow/fs.py", line 424, in open_input_stream
    raise FileNotFoundError(path)
FileNotFoundError: /home/ad2002/ray_results/train_2024-04-07_14-33-57/5_latent_size=128,batch_size=256,n_samples=500,num_workers=1,seed=0,learning_rate=0.0000,weight_decay=0.0000,log_every_n_steps=2,max_epochs=300/epoch=76-step=308.ckpt

[36m(train pid=1426258)[0m `Trainer.fit` stopped: `max_epochs=300` reached.
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      280            1483.25   0.346121 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:20:08. Total running time: 1hr 46min 10s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.34696412086486816 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      286            1514.6    0.346964 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:20:38. Total running time: 1hr 46min 40s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.34026333689689636 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      292            1545.93   0.340263 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-07 16:21:08. Total running time: 1hr 47min 10s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3374685049057007 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00003   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      297            1571.94   0.337469 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00004   PENDING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0                                        │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_5bb3b_00003 completed after 300 iterations at 2024-04-07 16:21:19. Total running time: 1hr 47min 21s
╭────────────────────────────────────────────╮
│ Trial train_5bb3b_00003 result             │
├────────────────────────────────────────────┤
│ checkpoint_dir_name                        │
│ time_this_iter_s                   5.21526 │
│ time_total_s                       1587.51 │
│ training_iteration                     300 │
│ loss                               0.33913 │
╰────────────────────────────────────────────╯

Trial train_5bb3b_00004 started with configuration:
╭──────────────────────────────────────────╮
│ Trial train_5bb3b_00004 config           │
├──────────────────────────────────────────┤
│ model/latent_size                    128 │
│ params/batch_size                    512 │
│ params/n_samples                     500 │
│ params/num_workers                     1 │
│ params/seed                            0 │
│ task_wrapper/learning_rate         1e-06 │
│ task_wrapper/weight_decay          1e-07 │
│ trainer/log_every_n_steps              2 │
│ trainer/max_epochs                   300 │
╰──────────────────────────────────────────╯

Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:21:38. Total running time: 1hr 47min 41s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0        1            13.0323   0.880397 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300          1615.04     0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300          1614.53     0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300          1587.51     0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:22:08. Total running time: 1hr 48min 11s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0        7            44.4358   0.880379 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300          1615.04     0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300          1614.53     0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300          1587.51     0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:22:38. Total running time: 1hr 48min 41s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       13             75.793   0.880361 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:23:08. Total running time: 1hr 49min 11s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       18             101.93   0.880346 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:23:38. Total running time: 1hr 49min 41s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       24            133.321   0.880328 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:24:08. Total running time: 1hr 50min 11s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       30            165.169   0.880312 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:24:38. Total running time: 1hr 50min 41s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       35            191.356   0.880298 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:25:08. Total running time: 1hr 51min 11s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       41            222.677   0.880281 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:25:38. Total running time: 1hr 51min 41s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       47            254.091   0.880264 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:26:08. Total running time: 1hr 52min 11s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       53             285.48   0.880249 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:26:39. Total running time: 1hr 52min 41s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       58            311.728   0.880236 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:27:09. Total running time: 1hr 53min 11s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       64            343.133   0.88022  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:27:39. Total running time: 1hr 53min 41s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       70            374.544   0.880206 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:28:09. Total running time: 1hr 54min 11s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       76            405.956   0.880191 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:28:39. Total running time: 1hr 54min 41s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       81            432.168   0.880178 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:29:09. Total running time: 1hr 55min 11s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       87            463.851   0.880163 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:29:39. Total running time: 1hr 55min 41s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       93            495.262   0.880147 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:30:09. Total running time: 1hr 56min 11s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0       99            526.683   0.880132 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:30:39. Total running time: 1hr 56min 41s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      104            552.906   0.880118 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:31:09. Total running time: 1hr 57min 11s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      110            584.269   0.880103 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:31:39. Total running time: 1hr 57min 41s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      116            615.702   0.880089 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:32:09. Total running time: 1hr 58min 12s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      121            641.815   0.880076 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:32:39. Total running time: 1hr 58min 42s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      127            673.223   0.880061 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:33:09. Total running time: 1hr 59min 12s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      133            704.576   0.880045 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:33:39. Total running time: 1hr 59min 42s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      139            736.015   0.880029 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:34:09. Total running time: 2hr 0min 12s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      144            762.679   0.880017 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:34:39. Total running time: 2hr 0min 42s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      150            794.048   0.880002 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:35:09. Total running time: 2hr 1min 12s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      156            825.392   0.879987 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:35:39. Total running time: 2hr 1min 42s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      162            856.943   0.879972 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:36:09. Total running time: 2hr 2min 12s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      167             883.09   0.879959 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:36:39. Total running time: 2hr 2min 42s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      173             914.49   0.879945 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:37:10. Total running time: 2hr 3min 12s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      179            945.848   0.87993  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:37:40. Total running time: 2hr 3min 42s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      185            977.177   0.879916 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:38:10. Total running time: 2hr 4min 12s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      190            1003.38   0.879904 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:38:40. Total running time: 2hr 4min 42s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      196            1034.74   0.879889 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:39:10. Total running time: 2hr 5min 12s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      202            1066.15   0.879875 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:39:40. Total running time: 2hr 5min 42s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      207            1092.38   0.879862 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:40:10. Total running time: 2hr 6min 12s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      213            1123.83   0.879847 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:40:40. Total running time: 2hr 6min 42s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      219            1155.22   0.879832 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:41:10. Total running time: 2hr 7min 12s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      225            1186.54   0.879817 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:41:40. Total running time: 2hr 7min 43s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      230            1212.69   0.879805 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:42:10. Total running time: 2hr 8min 13s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      236            1244.06   0.87979  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:42:40. Total running time: 2hr 8min 43s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      242            1275.48   0.879776 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:43:10. Total running time: 2hr 9min 13s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      248            1306.87   0.879761 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:43:40. Total running time: 2hr 9min 43s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      253            1332.99   0.879749 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:44:10. Total running time: 2hr 10min 13s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      259            1364.93   0.879735 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:44:40. Total running time: 2hr 10min 43s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      265            1396.37   0.87972  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:45:10. Total running time: 2hr 11min 13s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      271            1427.78   0.879706 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:45:40. Total running time: 2hr 11min 43s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      276            1454.02   0.879694 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:46:10. Total running time: 2hr 12min 13s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      282            1485.34   0.87968  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:46:41. Total running time: 2hr 12min 43s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      288            1516.82   0.879665 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:47:11. Total running time: 2hr 13min 13s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      293            1543.06   0.879653 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 1 PENDING
Current time: 2024-04-07 16:47:41. Total running time: 2hr 13min 43s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00004   RUNNING                       300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      299            1574.49   0.879639 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00005   PENDING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_5bb3b_00004 completed after 300 iterations at 2024-04-07 16:47:42. Total running time: 2hr 13min 45s
╭────────────────────────────────────────────╮
│ Trial train_5bb3b_00004 result             │
├────────────────────────────────────────────┤
│ checkpoint_dir_name                        │
│ time_this_iter_s                   5.23777 │
│ time_total_s                       1579.72 │
│ training_iteration                     300 │
│ loss                               0.87964 │
╰────────────────────────────────────────────╯

Trial train_5bb3b_00005 started with configuration:
╭──────────────────────────────────────────╮
│ Trial train_5bb3b_00005 config           │
├──────────────────────────────────────────┤
│ model/latent_size                    128 │
│ params/batch_size                    256 │
│ params/n_samples                     500 │
│ params/num_workers                     1 │
│ params/seed                            0 │
│ task_wrapper/learning_rate         1e-07 │
│ task_wrapper/weight_decay          1e-07 │
│ trainer/log_every_n_steps              2 │
│ trainer/max_epochs                   300 │
╰──────────────────────────────────────────╯

Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:48:11. Total running time: 2hr 14min 13s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0        3            23.5407   0.880399 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300          1615.04     0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300          1614.53     0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300          1587.51     0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300          1579.72     0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:48:41. Total running time: 2hr 14min 43s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0        9            55.0194   0.880397 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300          1615.04     0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300          1614.53     0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300          1587.51     0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300          1579.72     0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:49:11. Total running time: 2hr 15min 13s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       14            81.2339   0.880396 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300          1609.28     0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300          1615.04     0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300          1614.53     0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300          1587.51     0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300          1579.72     0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:49:41. Total running time: 2hr 15min 43s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       20            112.621   0.880394 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:50:11. Total running time: 2hr 16min 14s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       26            144.005   0.880392 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:50:41. Total running time: 2hr 16min 44s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       32            175.536   0.880391 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:51:11. Total running time: 2hr 17min 14s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       37            201.713   0.880389 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:51:41. Total running time: 2hr 17min 44s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       43            233.133   0.880387 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:52:11. Total running time: 2hr 18min 14s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       49             264.53   0.880386 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:52:41. Total running time: 2hr 18min 44s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       55            295.977   0.880384 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:53:11. Total running time: 2hr 19min 14s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       60            322.211   0.880383 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:53:41. Total running time: 2hr 19min 44s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       66            353.569   0.880381 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:54:11. Total running time: 2hr 20min 14s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       72            385.492   0.88038  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:54:41. Total running time: 2hr 20min 44s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       77            411.706   0.880378 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:55:12. Total running time: 2hr 21min 14s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       83            443.089   0.880377 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:55:42. Total running time: 2hr 21min 44s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       89            474.616   0.880375 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:56:12. Total running time: 2hr 22min 14s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0       95            505.898   0.880374 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:56:42. Total running time: 2hr 22min 44s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      100            532.107   0.880372 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:57:12. Total running time: 2hr 23min 14s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      106            563.568   0.88037  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:57:42. Total running time: 2hr 23min 44s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      112            594.985   0.880369 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:58:12. Total running time: 2hr 24min 14s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      118            626.423   0.880367 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:58:42. Total running time: 2hr 24min 44s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      123             652.65   0.880366 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:59:12. Total running time: 2hr 25min 15s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      129            684.114   0.880365 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 16:59:42. Total running time: 2hr 25min 45s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      135            715.621   0.880363 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:00:12. Total running time: 2hr 26min 15s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      140            741.789   0.880361 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:00:42. Total running time: 2hr 26min 45s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      146            773.098   0.88036  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:01:12. Total running time: 2hr 27min 15s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      152            804.499   0.880358 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:01:42. Total running time: 2hr 27min 45s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      158            835.865   0.880357 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:02:12. Total running time: 2hr 28min 15s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      163             862.01   0.880355 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:02:42. Total running time: 2hr 28min 45s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      169            893.411   0.880354 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:03:12. Total running time: 2hr 29min 15s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      175            924.804   0.880352 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:03:42. Total running time: 2hr 29min 45s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      181            956.208   0.88035  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:04:12. Total running time: 2hr 30min 15s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      186            982.841   0.880349 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300           1609.28    0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300           1615.04    0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300           1614.53    0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300           1587.51    0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300           1579.72    0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:04:42. Total running time: 2hr 30min 45s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      192            1014.21   0.880348 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:05:12. Total running time: 2hr 31min 15s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      198            1045.62   0.880346 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:05:43. Total running time: 2hr 31min 45s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      204            1077      0.880345 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:06:13. Total running time: 2hr 32min 15s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      209            1103.2    0.880343 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:06:43. Total running time: 2hr 32min 45s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      215            1134.52   0.880341 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:07:13. Total running time: 2hr 33min 15s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      221            1166.01   0.88034  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:07:43. Total running time: 2hr 33min 45s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      226            1192.16   0.880338 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:08:13. Total running time: 2hr 34min 15s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      232            1223.6    0.880337 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:08:43. Total running time: 2hr 34min 45s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      238            1254.95   0.880335 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:09:13. Total running time: 2hr 35min 15s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      244            1286.67   0.880334 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:09:43. Total running time: 2hr 35min 45s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      249            1312.8    0.880332 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:10:13. Total running time: 2hr 36min 15s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      255            1344.19   0.880331 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:10:43. Total running time: 2hr 36min 46s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      261            1375.58   0.880329 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:11:13. Total running time: 2hr 37min 16s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      267            1406.97   0.880327 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:11:43. Total running time: 2hr 37min 46s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      272            1433.1    0.880326 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:12:13. Total running time: 2hr 38min 16s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      278            1464.52   0.880324 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:12:43. Total running time: 2hr 38min 46s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      284            1495.93   0.880323 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:13:13. Total running time: 2hr 39min 16s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      290            1527.44   0.880321 │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING
Current time: 2024-04-07 17:13:43. Total running time: 2hr 39min 46s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00005   RUNNING                       300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      295            1553.62   0.88032  │
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_5bb3b_00005 completed after 300 iterations at 2024-04-07 17:14:06. Total running time: 2hr 40min 9s
╭────────────────────────────────────────────╮
│ Trial train_5bb3b_00005 result             │
├────────────────────────────────────────────┤
│ checkpoint_dir_name                        │
│ time_this_iter_s                   5.23969 │
│ time_total_s                        1580.4 │
│ training_iteration                     300 │
│ loss                               0.88032 │
╰────────────────────────────────────────────╯

Trial status: 6 TERMINATED
Current time: 2024-04-07 17:14:06. Total running time: 2hr 40min 9s
Logical resource usage: 4.0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)
Current best trial: 5bb3b_00003 with loss=0.3391340374946594 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.0001}, 'trainer': {'max_epochs': 300, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_5bb3b_00000   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   0.0001               0      300            1609.28   0.375927 │
│ train_5bb3b_00001   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-06                0      300            1615.04   0.879704 │
│ train_5bb3b_00002   TERMINATED                    300                        2                   256                      1                  500                   128                    0.001                   1e-07                0      300            1614.53   0.880325 │
│ train_5bb3b_00003   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   0.0001               0      300            1587.51   0.339134 │
│ train_5bb3b_00004   TERMINATED                    300                        2                   512                      1                  500                   128                    1e-07                   1e-06                0      300            1579.72   0.879637 │
│ train_5bb3b_00005   TERMINATED                    300                        2                   256                      1                  500                   128                    1e-07                   1e-07                0      300            1580.4    0.880319 │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

