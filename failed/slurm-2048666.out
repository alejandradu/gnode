2024-03-12 17:52:35,807	INFO worker.py:1724 -- Started a local Ray instance.
2024-03-12 17:52:49,490	INFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
2024-03-12 17:52:49,508	INFO tune.py:592 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949
2024-03-12 17:52:49,620	WARNING tune.py:916 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.
[36m(train pid=2305489)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=2305489)[0m The version_base parameter is not specified.
[36m(train pid=2305489)[0m Please specify a compatability version level, or None.
[36m(train pid=2305489)[0m Will assume defaults for version 1.1
[36m(train pid=2305489)[0m   with hydra.initialize(
[36m(train pid=2305489)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=2305489)[0m The version_base parameter is not specified.
[36m(train pid=2305489)[0m Please specify a compatability version level, or None.
[36m(train pid=2305489)[0m Will assume defaults for version 1.1
[36m(train pid=2305489)[0m   with hydra.initialize(
[36m(train pid=2305489)[0m [rank: 0] Seed set to 0
[36m(train pid=2305489)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=2305489)[0m GPU available: True (cuda), used: True
[36m(train pid=2305489)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=2305489)[0m IPU available: False, using: 0 IPUs
[36m(train pid=2305489)[0m HPU available: False, using: 0 HPUs
[36m(train pid=2305489)[0m You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[36m(train pid=2305489)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=2305489)[0m wandb: Network error (ConnectionError), entering retry loop.
[36m(train pid=2305489)[0m wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: Network error (ConnectionError), entering retry loop.
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: \ Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: | Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: / Waiting for wandb.init()...
[36m(train pid=2305489)[0m wandb: - Waiting for wandb.init()...
2024-03-12 17:54:31,867	ERROR tune_controller.py:1374 -- Trial task failed for trial train_d44cf_00000
Traceback (most recent call last):
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py", line 110, in resolve_future
    result = ray.get(future)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/_private/worker.py", line 2624, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(CommError): [36mray::ImplicitFunc.train()[39m (pid=2305489, ip=172.21.1.129, actor_id=5bbb33125b3904fce9c7b40d01000000, repr=train)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 342, in train
    raise skipped from exception_cause(skipped)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/air/_internal/util.py", line 88, in run
    self._ret = self._target(*self._args, **self._kwargs)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 115, in <lambda>
    training_func=lambda: self._trainable_func(self.config),
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py", line 332, in _trainable_func
    output = fn()
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/trainable/util.py", line 138, in inner
    return trainable(config, **fn_kwargs)
  File "/home/ad2002/gnode/ctd/task_modeling/task_train_prep.py", line 168, in train
    trainer.fit(model=task_wrapper, datamodule=datamodule)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 950, in _run
    call._call_setup_hook(self)  # allow user to setup lightning_module in accelerator environment
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 86, in _call_setup_hook
    if hasattr(logger, "experiment"):
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/logger.py", line 118, in experiment
    return fn(self)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py", line 399, in experiment
    self._experiment = wandb.init(**self._wandb_init)
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1195, in init
    raise e
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1176, in init
    run = wi.init()
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 785, in init
    raise error
wandb.errors.CommError: Run initialization has timed out after 90.0 sec. 
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
╭──────────────────────────────────────────────────────────────╮
│ Configuration for experiment     train_2024-03-12_17-52-49   │
├──────────────────────────────────────────────────────────────┤
│ Search algorithm                 BasicVariantGenerator       │
│ Scheduler                        FIFOScheduler               │
│ Number of trials                 1                           │
╰──────────────────────────────────────────────────────────────╯

View detailed results here: /scratch/network/ad2002/content/runs/task-trained/20240312_NODE_NBFF_Test/train_2024-03-12_17-52-49
To visualize your results with TensorBoard, run: `tensorboard --logdir /home/ad2002/ray_results/train_2024-03-12_17-52-49`

Trial status: 1 PENDING
Current time: 2024-03-12 17:52:49. Total running time: 0s
Logical resource usage: 0/48 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100)
╭──────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...pper/weight_decay     params/seed │
├──────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_d44cf_00000   PENDING                     150                    1e-08               0 │
╰──────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_d44cf_00000 started with configuration:
╭──────────────────────────────────────────╮
│ Trial train_d44cf_00000 config           │
├──────────────────────────────────────────┤
│ params/seed                            0 │
│ task_wrapper/weight_decay          1e-08 │
│ trainer/max_epochs                   150 │
╰──────────────────────────────────────────╯

Trial status: 1 RUNNING
Current time: 2024-03-12 17:53:20. Total running time: 30s
Logical resource usage: 8.0/48 CPUs, 0.9/1 GPUs (0.0/1.0 accelerator_type:A100)
╭──────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...pper/weight_decay     params/seed │
├──────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_d44cf_00000   RUNNING                     150                    1e-08               0 │
╰──────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2024-03-12 17:53:50. Total running time: 1min 0s
Logical resource usage: 8.0/48 CPUs, 0.9/1 GPUs (0.0/1.0 accelerator_type:A100)
╭──────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...pper/weight_decay     params/seed │
├──────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_d44cf_00000   RUNNING                     150                    1e-08               0 │
╰──────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING
Current time: 2024-03-12 17:54:20. Total running time: 1min 30s
Logical resource usage: 8.0/48 CPUs, 0.9/1 GPUs (0.0/1.0 accelerator_type:A100)
╭──────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...pper/weight_decay     params/seed │
├──────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_d44cf_00000   RUNNING                     150                    1e-08               0 │
╰──────────────────────────────────────────────────────────────────────────────────────────────╯
[36m(train pid=2305489)[0m Problem at: /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py 399 experiment

Trial train_d44cf_00000 errored after 0 iterations at 2024-03-12 17:54:31. Total running time: 1min 42s
Error file: /home/ad2002/ray_results/train_2024-03-12_17-52-49/0_seed=0,weight_decay=0.0000,max_epochs=150/error.txt

Trial status: 1 ERROR
Current time: 2024-03-12 17:54:32. Total running time: 1min 42s
Logical resource usage: 8.0/48 CPUs, 0.9/1 GPUs (0.0/1.0 accelerator_type:A100)
╭──────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...pper/weight_decay     params/seed │
├──────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_d44cf_00000   ERROR                       150                    1e-08               0 │
╰──────────────────────────────────────────────────────────────────────────────────────────────╯

Number of errored trials: 1
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name            # failures   error file                                                                                               │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_d44cf_00000              1   /home/ad2002/ray_results/train_2024-03-12_17-52-49/0_seed=0,weight_decay=0.0000,max_epochs=150/error.txt │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Traceback (most recent call last):
  File "/home/ad2002/gnode/examples/run_task_training.py", line 128, in <module>
    main(
  File "/home/ad2002/gnode/examples/run_task_training.py", line 103, in main
    tune.run(
  File "/home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/tune.py", line 1036, in run
    raise TuneError("Trials did not complete", incomplete_trials)
ray.tune.error.TuneError: ('Trials did not complete', [train_d44cf_00000])
