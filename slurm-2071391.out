2024-04-16 21:51:31,376	INFO worker.py:1724 -- Started a local Ray instance.
2024-04-16 21:51:54,209	INFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.
2024-04-16 21:51:54,211	INFO tune.py:592 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949
2024-04-16 21:51:54,232	WARNING tune.py:916 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.
[36m(train pid=396575)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=396575)[0m The version_base parameter is not specified.
[36m(train pid=396575)[0m Please specify a compatability version level, or None.
[36m(train pid=396575)[0m Will assume defaults for version 1.1
[36m(train pid=396575)[0m   with hydra.initialize(
[36m(train pid=396575)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=396575)[0m The version_base parameter is not specified.
[36m(train pid=396575)[0m Please specify a compatability version level, or None.
[36m(train pid=396575)[0m Will assume defaults for version 1.1
[36m(train pid=396575)[0m   with hydra.initialize(
[36m(train pid=396575)[0m [rank: 0] Seed set to 0
[36m(train pid=396575)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=396575)[0m GPU available: True (cuda), used: True
[36m(train pid=396575)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=396575)[0m IPU available: False, using: 0 IPUs
[36m(train pid=396575)[0m HPU available: False, using: 0 HPUs
[36m(train pid=396575)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=396575)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-16_21-51-54/0_latent_size=128,batch_size=512,n_samples=500,num_workers=1,seed=0,learning_rate=0.0010,weight_decay=0.0000,log_every_n_steps=2,max_epochs=200 exists and is not empty.
[36m(train pid=396575)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=396575)[0m 
[36m(train pid=396575)[0m   | Name  | Type    | Params
[36m(train pid=396575)[0m ----------------------------------
[36m(train pid=396575)[0m 0 | model | GRU_RNN | 50.4 K
[36m(train pid=396575)[0m ----------------------------------
[36m(train pid=396575)[0m 50.4 K    Trainable params
[36m(train pid=396575)[0m 0         Non-trainable params
[36m(train pid=396575)[0m 50.4 K    Total params
[36m(train pid=396575)[0m 0.202     Total estimated model params size (MB)
[36m(train pid=396575)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=396575)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=396575)[0m   warnings.warn(_create_warning_msg(
[36m(train pid=396575)[0m `Trainer.fit` stopped: `max_epochs=200` reached.
[36m(train pid=492699)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=492699)[0m The version_base parameter is not specified.
[36m(train pid=492699)[0m Please specify a compatability version level, or None.
[36m(train pid=492699)[0m Will assume defaults for version 1.1
[36m(train pid=492699)[0m   with hydra.initialize(
[36m(train pid=492699)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=492699)[0m The version_base parameter is not specified.
[36m(train pid=492699)[0m Please specify a compatability version level, or None.
[36m(train pid=492699)[0m Will assume defaults for version 1.1
[36m(train pid=492699)[0m   with hydra.initialize(
[36m(train pid=492699)[0m [rank: 0] Seed set to 0
[36m(train pid=492699)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=492699)[0m GPU available: True (cuda), used: True
[36m(train pid=492699)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=492699)[0m IPU available: False, using: 0 IPUs
[36m(train pid=492699)[0m HPU available: False, using: 0 HPUs
[36m(train pid=492699)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=492699)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-16_21-51-54/1_latent_size=256,batch_size=512,n_samples=500,num_workers=1,seed=0,learning_rate=0.0010,weight_decay=0.0000,log_every_n_steps=2,max_epochs=200 exists and is not empty.
[36m(train pid=492699)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=492699)[0m 
[36m(train pid=492699)[0m   | Name  | Type    | Params
[36m(train pid=492699)[0m ----------------------------------
[36m(train pid=492699)[0m 0 | model | GRU_RNN | 199 K 
[36m(train pid=492699)[0m ----------------------------------
[36m(train pid=492699)[0m 199 K     Trainable params
[36m(train pid=492699)[0m 0         Non-trainable params
[36m(train pid=492699)[0m 199 K     Total params
[36m(train pid=492699)[0m 0.797     Total estimated model params size (MB)
[36m(train pid=492699)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=492699)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=492699)[0m   warnings.warn(_create_warning_msg(
[36m(train pid=492699)[0m `Trainer.fit` stopped: `max_epochs=200` reached.
[36m(train pid=587211)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=587211)[0m The version_base parameter is not specified.
[36m(train pid=587211)[0m Please specify a compatability version level, or None.
[36m(train pid=587211)[0m Will assume defaults for version 1.1
[36m(train pid=587211)[0m   with hydra.initialize(
[36m(train pid=587211)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=587211)[0m The version_base parameter is not specified.
[36m(train pid=587211)[0m Please specify a compatability version level, or None.
[36m(train pid=587211)[0m Will assume defaults for version 1.1
[36m(train pid=587211)[0m   with hydra.initialize(
[36m(train pid=587211)[0m [rank: 0] Seed set to 0
[36m(train pid=587211)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=587211)[0m GPU available: True (cuda), used: True
[36m(train pid=587211)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=587211)[0m IPU available: False, using: 0 IPUs
[36m(train pid=587211)[0m HPU available: False, using: 0 HPUs
[36m(train pid=587211)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=587211)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-16_21-51-54/2_latent_size=128,batch_size=512,n_samples=500,num_workers=1,seed=0,learning_rate=0.0100,weight_decay=0.0000,log_every_n_steps=2,max_epochs=200 exists and is not empty.
[36m(train pid=587211)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=587211)[0m 
[36m(train pid=587211)[0m   | Name  | Type    | Params
[36m(train pid=587211)[0m ----------------------------------
[36m(train pid=587211)[0m 0 | model | GRU_RNN | 50.4 K
[36m(train pid=587211)[0m ----------------------------------
[36m(train pid=587211)[0m 50.4 K    Trainable params
[36m(train pid=587211)[0m 0         Non-trainable params
[36m(train pid=587211)[0m 50.4 K    Total params
[36m(train pid=587211)[0m 0.202     Total estimated model params size (MB)
[36m(train pid=587211)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=587211)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=587211)[0m   warnings.warn(_create_warning_msg(
[36m(train pid=587211)[0m `Trainer.fit` stopped: `max_epochs=200` reached.
╭──────────────────────────────────────────────────────────────╮
│ Configuration for experiment     train_2024-04-16_21-51-54   │
├──────────────────────────────────────────────────────────────┤
│ Search algorithm                 BasicVariantGenerator       │
│ Scheduler                        FIFOScheduler               │
│ Number of trials                 8                           │
╰──────────────────────────────────────────────────────────────╯

View detailed results here: /scratch/network/ad2002/content/runs/task-trained/20240416_GRU_OBS_200epoch_moreparams/train_2024-04-16_21-51-54
To visualize your results with TensorBoard, run: `tensorboard --logdir /home/ad2002/ray_results/train_2024-04-16_21-51-54`

Trial status: 8 PENDING
Current time: 2024-04-16 21:51:54. Total running time: 0s
Logical resource usage: 0/56 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:V100)
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0 │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0 │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0 │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0 │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0 │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0 │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_014ea_00000 started with configuration:
╭──────────────────────────────────────────╮
│ Trial train_014ea_00000 config           │
├──────────────────────────────────────────┤
│ model/latent_size                    128 │
│ params/batch_size                    512 │
│ params/n_samples                     500 │
│ params/num_workers                     1 │
│ params/seed                            0 │
│ task_wrapper/learning_rate         0.001 │
│ task_wrapper/weight_decay          1e-07 │
│ trainer/log_every_n_steps              2 │
│ trainer/max_epochs                   200 │
╰──────────────────────────────────────────╯

Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:52:24. Total running time: 30s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed │
├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0 │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0 │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0 │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0 │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0 │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0 │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0 │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:52:54. Total running time: 1min 0s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.8746097087860107 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0        3            47.4164   0.87461 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                       │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                       │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                       │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                       │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                       │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                       │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:53:24. Total running time: 1min 30s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.8649408221244812 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0        7            83.7631   0.864941 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:53:54. Total running time: 2min 0s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.7646390795707703 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       10            110.892   0.764639 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:54:24. Total running time: 2min 30s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3830089867115021 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       13            139.125   0.383009 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:54:54. Total running time: 3min 0s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.46740853786468506 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       17            175.303   0.467409 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:55:24. Total running time: 3min 30s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.6819272637367249 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       20            203.326   0.681927 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:55:54. Total running time: 4min 0s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.4935731887817383 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       23            230.467   0.493573 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:56:24. Total running time: 4min 30s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.5000897645950317 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       26              257.6   0.50009 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                       │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                       │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                       │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                       │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                       │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                       │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:56:54. Total running time: 5min 0s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.47184962034225464 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       30            294.227   0.47185 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                       │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                       │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                       │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                       │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                       │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                       │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:57:25. Total running time: 5min 30s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.558800220489502 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)     loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       33            321.388   0.5588 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                      │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                      │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                      │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                      │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                      │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                      │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                      │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:57:55. Total running time: 6min 0s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.4244455397129059 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       36            348.503   0.424446 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:58:25. Total running time: 6min 30s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.44794127345085144 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       40            385.656   0.447941 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:58:55. Total running time: 7min 0s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.37104061245918274 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       43            412.788   0.371041 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:59:25. Total running time: 7min 30s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.5231916904449463 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       46            439.896   0.523192 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 21:59:55. Total running time: 8min 1s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.38874202966690063 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       49            467.877   0.388742 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:00:25. Total running time: 8min 31s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.40100720524787903 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       53            503.946   0.401007 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:00:55. Total running time: 9min 1s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.351523756980896 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       56            530.985   0.351524 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:01:25. Total running time: 9min 31s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3518308401107788 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       59            558.003   0.351831 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:01:55. Total running time: 10min 1s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.397239089012146 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       63            595.456   0.397239 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:02:25. Total running time: 10min 31s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.41467511653900146 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       66            622.567   0.414675 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:02:55. Total running time: 11min 1s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.445675253868103 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       69            650.557   0.445675 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:03:25. Total running time: 11min 31s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3368793725967407 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       72            678.149   0.336879 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:03:55. Total running time: 12min 1s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.34343546628952026 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       76            714.807   0.343435 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:04:25. Total running time: 12min 31s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.33448249101638794 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       79            741.856   0.334482 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:04:55. Total running time: 13min 1s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3804068863391876 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       82            768.762   0.380407 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:05:25. Total running time: 13min 31s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.36590853333473206 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       86            805.088   0.365909 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:05:55. Total running time: 14min 1s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.48217669129371643 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       89            832.734   0.482177 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:06:25. Total running time: 14min 31s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.339072585105896 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       92            859.832   0.339073 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:06:55. Total running time: 15min 1s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.357632040977478 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       96            895.928   0.357632 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:07:25. Total running time: 15min 31s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.33270263671875 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0       99            923.358   0.332703 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:07:56. Total running time: 16min 1s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3617205321788788 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      102             950.41   0.361721 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:08:26. Total running time: 16min 31s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.42597562074661255 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      105            977.439   0.425976 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:08:56. Total running time: 17min 1s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3400738835334778 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      109            1013.57   0.340074 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:09:26. Total running time: 17min 31s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.35403117537498474 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      112            1041.31   0.354031 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:09:56. Total running time: 18min 1s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3503585457801819 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      115            1068.31   0.350359 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:10:26. Total running time: 18min 31s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.36793944239616394 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      119            1104.37   0.367939 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:10:56. Total running time: 19min 1s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3371342420578003 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      122            1131.75   0.337134 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:11:26. Total running time: 19min 32s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3267917335033417 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      125            1158.82   0.326792 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:11:56. Total running time: 20min 2s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3215802013874054 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      128            1188.32   0.32158 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                       │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                       │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                       │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                       │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                       │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                       │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:12:26. Total running time: 20min 32s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.325568288564682 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      132            1224.45   0.325568 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:12:56. Total running time: 21min 2s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.33991870284080505 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      135            1252.06   0.339919 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:13:26. Total running time: 21min 32s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.34469977021217346 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)     loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      138            1279.98   0.3447 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                      │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                      │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                      │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                      │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                      │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                      │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                      │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:13:56. Total running time: 22min 2s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3155222237110138 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      141            1307.24   0.315522 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:14:26. Total running time: 22min 32s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.37284961342811584 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      145            1344.17   0.37285 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                       │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                       │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                       │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                       │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                       │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                       │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:14:56. Total running time: 23min 2s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3331817388534546 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      148            1371.29   0.333182 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:15:26. Total running time: 23min 32s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.33307361602783203 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      151            1398.35   0.333074 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:15:56. Total running time: 24min 2s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.41675999760627747 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)      loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      155            1435.16   0.41676 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                       │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                       │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                       │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                       │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                       │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                       │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                       │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:16:26. Total running time: 24min 32s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3215722143650055 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      158             1462.9   0.321572 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:16:56. Total running time: 25min 2s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.32551831007003784 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      161            1489.91   0.325518 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:17:26. Total running time: 25min 32s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.32395708560943604 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      165            1526.11   0.323957 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:17:56. Total running time: 26min 2s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.31260600686073303 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      168            1553.15   0.312606 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:18:27. Total running time: 26min 32s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.33517566323280334 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      171            1581.08   0.335176 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:18:57. Total running time: 27min 2s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.34078875184059143 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      175             1617.1   0.340789 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:19:27. Total running time: 27min 32s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3367839455604553 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      178            1644.26   0.336784 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:19:57. Total running time: 28min 2s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.33931365609169006 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      181            1671.31   0.339314 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:20:27. Total running time: 28min 32s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.32868820428848267 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      184            1699.09   0.328688 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:20:57. Total running time: 29min 2s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.40225112438201904 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      188            1736.25   0.402251 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:21:27. Total running time: 29min 33s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.3320947289466858 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      191            1763.29   0.332095 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:21:57. Total running time: 30min 3s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.315228670835495 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      194            1792.21   0.315229 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:22:27. Total running time: 30min 33s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.32257765531539917 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      197            1819.49   0.322578 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 RUNNING | 7 PENDING
Current time: 2024-04-16 22:22:57. Total running time: 31min 3s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status       trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00000   RUNNING                     200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00002   PENDING                     200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                     200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                     200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                     200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_014ea_00000 completed after 200 iterations at 2024-04-16 22:23:01. Total running time: 31min 7s
╭────────────────────────────────────────────╮
│ Trial train_014ea_00000 result             │
├────────────────────────────────────────────┤
│ checkpoint_dir_name                        │
│ time_this_iter_s                   9.01667 │
│ time_total_s                       1846.62 │
│ training_iteration                     200 │
│ loss                                0.3134 │
╰────────────────────────────────────────────╯

Trial train_014ea_00001 started with configuration:
╭──────────────────────────────────────────╮
│ Trial train_014ea_00001 config           │
├──────────────────────────────────────────┤
│ model/latent_size                    256 │
│ params/batch_size                    512 │
│ params/n_samples                     500 │
│ params/num_workers                     1 │
│ params/seed                            0 │
│ task_wrapper/learning_rate         0.001 │
│ task_wrapper/weight_decay          1e-07 │
│ trainer/log_every_n_steps              2 │
│ trainer/max_epochs                   200 │
╰──────────────────────────────────────────╯

Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:23:27. Total running time: 31min 33s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0                                        │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:23:57. Total running time: 32min 3s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0        3            42.8893   0.874465 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200          1846.62     0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:24:27. Total running time: 32min 33s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0        6            71.7699   0.86326  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200          1846.62     0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:24:57. Total running time: 33min 3s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       10            110.604   0.681299 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:25:27. Total running time: 33min 33s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       13            139.816   0.787521 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:25:57. Total running time: 34min 3s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       16             170.35   0.740857 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:26:27. Total running time: 34min 33s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       19            199.245   0.593829 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:26:57. Total running time: 35min 3s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       22            228.092   0.444702 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:27:27. Total running time: 35min 33s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       25            258.024   0.611284 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:27:57. Total running time: 36min 3s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       28            287.131   1.01053  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:28:27. Total running time: 36min 33s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       31            316.194   0.796077 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:28:58. Total running time: 37min 3s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       34            346.383   0.512134 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:29:28. Total running time: 37min 33s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       37            375.243   0.488493 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:29:58. Total running time: 38min 3s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       40            404.146   0.433388 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:30:28. Total running time: 38min 33s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       43            432.971   0.414571 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:30:58. Total running time: 39min 3s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       46            461.896   0.386555 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:31:28. Total running time: 39min 34s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       50            500.485   0.370402 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:31:58. Total running time: 40min 4s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       53            531.032   0.500826 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:32:28. Total running time: 40min 34s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       56            559.818   0.661511 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:32:58. Total running time: 41min 4s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       59            590.107   0.556258 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:33:28. Total running time: 41min 34s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       62            619.003   0.36195  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:33:58. Total running time: 42min 4s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       65            648.913   0.433917 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:34:28. Total running time: 42min 34s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       68            677.679   0.40555  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:34:58. Total running time: 43min 4s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       71            707.429   0.367111 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:35:28. Total running time: 43min 34s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       74             736.93   0.337945 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:35:58. Total running time: 44min 4s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       77            766.215   0.366038 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:36:28. Total running time: 44min 34s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       80            795.061   0.389945 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:36:58. Total running time: 45min 4s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       83            823.949   0.342987 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:37:28. Total running time: 45min 34s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       86            852.855   0.373421 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:37:58. Total running time: 46min 4s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       90            891.337   0.33183  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:38:28. Total running time: 46min 34s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       93            921.298   0.365798 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:38:58. Total running time: 47min 4s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       96            950.224   0.392075 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:39:29. Total running time: 47min 34s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0       99            980.061   0.586461 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:39:59. Total running time: 48min 4s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      102            1008.95   0.578833 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:40:29. Total running time: 48min 34s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      105            1037.81   0.32403  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:40:59. Total running time: 49min 4s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      108            1068.22   0.363681 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:41:29. Total running time: 49min 35s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      111            1098.15   0.316661 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:41:59. Total running time: 50min 5s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      114            1128.59   0.329567 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:42:29. Total running time: 50min 35s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      117            1157.78   0.354779 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:42:59. Total running time: 51min 5s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      120            1186.65   0.314036 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:43:29. Total running time: 51min 35s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.3105296492576599 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      123            1215.57   0.31053  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:43:59. Total running time: 52min 5s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      126            1244.4    0.316582 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:44:29. Total running time: 52min 35s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      129            1273.24   0.506247 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:44:59. Total running time: 53min 5s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      133            1312.49   0.331689 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:45:29. Total running time: 53min 35s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      136            1341.37   0.317503 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:45:59. Total running time: 54min 5s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      139            1370.37   0.386034 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:46:29. Total running time: 54min 35s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.3038448095321655 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      142            1400.41   0.303845 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:46:59. Total running time: 55min 5s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      145            1430.87   0.342444 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:47:29. Total running time: 55min 35s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.31189072132110596 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      148            1461.18   0.311891 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:47:59. Total running time: 56min 5s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      151            1491.21   0.323801 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:48:29. Total running time: 56min 35s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      154            1521.24   0.329708 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:49:00. Total running time: 57min 5s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      157            1550.18   0.445246 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:49:30. Total running time: 57min 35s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      160            1579.7    0.390969 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:50:00. Total running time: 58min 5s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.3081947863101959 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      163            1609.25   0.308195 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:50:30. Total running time: 58min 35s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.29992714524269104 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      166            1638.65   0.299927 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:51:00. Total running time: 59min 6s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      169            1667.73   0.368817 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:51:30. Total running time: 59min 36s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      172            1697.11   0.334367 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:52:00. Total running time: 1hr 0min 6s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      175            1727.57   0.320324 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:52:30. Total running time: 1hr 0min 36s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      178            1756.54   0.316562 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:53:00. Total running time: 1hr 1min 6s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      181            1786.22   0.344707 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:53:30. Total running time: 1hr 1min 36s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.3013812303543091 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      184            1815.23   0.301381 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:54:00. Total running time: 1hr 2min 6s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      187            1845.14   0.324299 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:54:30. Total running time: 1hr 2min 36s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2866289019584656 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      190            1875.87   0.286629 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:55:00. Total running time: 1hr 3min 6s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00000 with loss=0.313403844833374 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      193            1904.7    0.325902 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:55:30. Total running time: 1hr 3min 36s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2951362729072571 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      196            1934.45   0.295136 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 1 TERMINATED | 1 RUNNING | 6 PENDING
Current time: 2024-04-16 22:56:00. Total running time: 1hr 4min 6s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00001   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00002   PENDING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_014ea_00001 completed after 200 iterations at 2024-04-16 22:56:20. Total running time: 1hr 4min 26s
╭────────────────────────────────────────────╮
│ Trial train_014ea_00001 result             │
├────────────────────────────────────────────┤
│ checkpoint_dir_name                        │
│ time_this_iter_s                   9.66089 │
│ time_total_s                       1973.03 │
│ training_iteration                     200 │
│ loss                               0.29891 │
╰────────────────────────────────────────────╯

Trial train_014ea_00002 started with configuration:
╭──────────────────────────────────────────╮
│ Trial train_014ea_00002 config           │
├──────────────────────────────────────────┤
│ model/latent_size                    128 │
│ params/batch_size                    512 │
│ params/n_samples                     500 │
│ params/num_workers                     1 │
│ params/seed                            0 │
│ task_wrapper/learning_rate          0.01 │
│ task_wrapper/weight_decay          1e-07 │
│ trainer/log_every_n_steps              2 │
│ trainer/max_epochs                   200 │
╰──────────────────────────────────────────╯

Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 22:56:30. Total running time: 1hr 4min 36s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0                                        │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 22:57:00. Total running time: 1hr 5min 6s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0        2            32.0338   0.878894 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200          1846.62     0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200          1973.03     0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 22:57:31. Total running time: 1hr 5min 36s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0        5              59.37   1.65317  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 22:58:01. Total running time: 1hr 6min 6s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0        8            86.6194   0.898935 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200          1846.62     0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200          1973.03     0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 22:58:31. Total running time: 1hr 6min 36s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       12            124.032   0.81046  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 22:59:01. Total running time: 1hr 7min 7s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       15             151.59   0.575658 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 22:59:31. Total running time: 1hr 7min 37s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       18            180.122   0.451207 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:00:01. Total running time: 1hr 8min 7s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       21             207.49   0.41362  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:00:31. Total running time: 1hr 8min 37s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       25            243.776   0.388208 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:01:01. Total running time: 1hr 9min 7s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       28            271.095   0.422702 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:01:31. Total running time: 1hr 9min 37s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       31            298.951   0.391411 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:02:01. Total running time: 1hr 10min 7s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       34            327.204   0.335846 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:02:31. Total running time: 1hr 10min 37s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       38            365.313   0.429879 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:03:01. Total running time: 1hr 11min 7s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       41            392.958   0.371959 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:03:31. Total running time: 1hr 11min 37s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       44             420.27   0.340784 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:04:01. Total running time: 1hr 12min 7s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       47            447.525   0.369887 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:04:32. Total running time: 1hr 12min 37s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       51            483.818   0.477039 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:05:02. Total running time: 1hr 13min 7s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       54             511.02   0.344629 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:05:32. Total running time: 1hr 13min 37s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       57            538.261   0.45377  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:06:02. Total running time: 1hr 14min 7s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       61            575.543   0.299204 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:06:32. Total running time: 1hr 14min 37s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       64             602.86   0.30257  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:07:02. Total running time: 1hr 15min 7s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       67            630.044   0.572268 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:07:32. Total running time: 1hr 15min 38s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.2875921130180359 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       70             657.31   0.287592 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:08:02. Total running time: 1hr 16min 8s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.25757408142089844 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       74            694.389   0.257574 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:08:32. Total running time: 1hr 16min 38s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.253412663936615 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       77            721.533   0.253413 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:09:02. Total running time: 1hr 17min 8s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.24800091981887817 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       80            749.431   0.248001 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:09:32. Total running time: 1hr 17min 38s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       84            786.317   0.333887 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:10:02. Total running time: 1hr 18min 8s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       87            813.551   0.389764 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:10:32. Total running time: 1hr 18min 38s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.23230718076229095 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       90            841.658   0.232307 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:11:02. Total running time: 1hr 19min 8s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.20144474506378174 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       93            869.273   0.201445 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:11:32. Total running time: 1hr 19min 38s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0       97            906.541   0.346912 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:12:02. Total running time: 1hr 20min 8s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.1885615587234497 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      100            933.833   0.188562 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:12:32. Total running time: 1hr 20min 38s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.2774612009525299 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      103            961.068   0.277461 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:13:02. Total running time: 1hr 21min 8s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.17002373933792114 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      106            988.257   0.170024 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:13:32. Total running time: 1hr 21min 38s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.2756696045398712 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      110            1024.64   0.27567  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:14:02. Total running time: 1hr 22min 8s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      113            1051.82   0.366483 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:14:33. Total running time: 1hr 22min 38s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.248167023062706 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      116            1080      0.248167 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:15:03. Total running time: 1hr 23min 8s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00001 with loss=0.2989135980606079 and params={'model': {'latent_size': 256}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.001}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      119            1107.94   0.454204 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:15:33. Total running time: 1hr 23min 38s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.16666369140148163 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      123            1144.21   0.166664 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:16:03. Total running time: 1hr 24min 8s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.20232418179512024 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      126            1172.32   0.202324 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:16:33. Total running time: 1hr 24min 38s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.20065928995609283 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      129            1199.6    0.200659 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:17:03. Total running time: 1hr 25min 9s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.20353083312511444 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      133            1236.71   0.203531 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:17:33. Total running time: 1hr 25min 39s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.2522277235984802 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      136            1264.93   0.252228 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:18:03. Total running time: 1hr 26min 9s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.15988358855247498 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      139            1292.07   0.159884 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:18:33. Total running time: 1hr 26min 39s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.1411266326904297 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      142            1319.67   0.141127 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:19:03. Total running time: 1hr 27min 9s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.13876648247241974 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      146            1356.49   0.138766 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:19:33. Total running time: 1hr 27min 39s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.12466521561145782 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      149            1384.47   0.124665 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:20:03. Total running time: 1hr 28min 9s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.12341302633285522 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      152            1412.22   0.123413 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:20:33. Total running time: 1hr 28min 39s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.13395477831363678 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      155            1439.79   0.133955 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:21:03. Total running time: 1hr 29min 9s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.12712587416172028 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      159            1476.86   0.127126 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:21:33. Total running time: 1hr 29min 39s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.1570253074169159 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      162            1504.03   0.157025 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:22:03. Total running time: 1hr 30min 9s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.13026806712150574 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      165            1532.27   0.130268 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:22:33. Total running time: 1hr 30min 39s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.12593905627727509 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      168            1559.4    0.125939 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:23:03. Total running time: 1hr 31min 9s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.12091163545846939 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      172            1596.47   0.120912 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:23:33. Total running time: 1hr 31min 39s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.10598184913396835 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      175            1624.09   0.105982 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:24:03. Total running time: 1hr 32min 9s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.11046954989433289 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      178            1651.47   0.11047  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:24:33. Total running time: 1hr 32min 39s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.10768287628889084 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      181            1678.76   0.107683 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:25:04. Total running time: 1hr 33min 9s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.12191013246774673 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      185            1715.04   0.12191  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:25:34. Total running time: 1hr 33min 39s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.14223432540893555 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      188            1742.2    0.142234 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:26:04. Total running time: 1hr 34min 9s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.0999608263373375 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      191            1769.59   0.0999608 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                         │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:26:34. Total running time: 1hr 34min 39s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.0976729467511177 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      195            1805.85   0.0976729 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                         │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:27:04. Total running time: 1hr 35min 9s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.10195863991975784 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
[36m(train pid=686218)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=686218)[0m The version_base parameter is not specified.
[36m(train pid=686218)[0m Please specify a compatability version level, or None.
[36m(train pid=686218)[0m Will assume defaults for version 1.1
[36m(train pid=686218)[0m   with hydra.initialize(
[36m(train pid=686218)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=686218)[0m The version_base parameter is not specified.
[36m(train pid=686218)[0m Please specify a compatability version level, or None.
[36m(train pid=686218)[0m Will assume defaults for version 1.1
[36m(train pid=686218)[0m   with hydra.initialize(
[36m(train pid=686218)[0m [rank: 0] Seed set to 0
[36m(train pid=686218)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=686218)[0m GPU available: True (cuda), used: True
[36m(train pid=686218)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=686218)[0m IPU available: False, using: 0 IPUs
[36m(train pid=686218)[0m HPU available: False, using: 0 HPUs
[36m(train pid=686218)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=686218)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-16_21-51-54/3_latent_size=256,batch_size=512,n_samples=500,num_workers=1,seed=0,learning_rate=0.0100,weight_decay=0.0000,log_every_n_steps=2,max_epochs=200 exists and is not empty.
[36m(train pid=686218)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=686218)[0m 
[36m(train pid=686218)[0m   | Name  | Type    | Params
[36m(train pid=686218)[0m ----------------------------------
[36m(train pid=686218)[0m 0 | model | GRU_RNN | 199 K 
[36m(train pid=686218)[0m ----------------------------------
[36m(train pid=686218)[0m 199 K     Trainable params
[36m(train pid=686218)[0m 0         Non-trainable params
[36m(train pid=686218)[0m 199 K     Total params
[36m(train pid=686218)[0m 0.797     Total estimated model params size (MB)
[36m(train pid=686218)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=686218)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=686218)[0m   warnings.warn(_create_warning_msg(
[36m(train pid=686218)[0m `Trainer.fit` stopped: `max_epochs=200` reached.
[36m(train pid=784471)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=784471)[0m The version_base parameter is not specified.
[36m(train pid=784471)[0m Please specify a compatability version level, or None.
[36m(train pid=784471)[0m Will assume defaults for version 1.1
[36m(train pid=784471)[0m   with hydra.initialize(
[36m(train pid=784471)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=784471)[0m The version_base parameter is not specified.
[36m(train pid=784471)[0m Please specify a compatability version level, or None.
[36m(train pid=784471)[0m Will assume defaults for version 1.1
[36m(train pid=784471)[0m   with hydra.initialize(
[36m(train pid=784471)[0m [rank: 0] Seed set to 0
[36m(train pid=784471)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=784471)[0m GPU available: True (cuda), used: True
[36m(train pid=784471)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=784471)[0m IPU available: False, using: 0 IPUs
[36m(train pid=784471)[0m HPU available: False, using: 0 HPUs
[36m(train pid=784471)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=784471)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-16_21-51-54/4_latent_size=128,batch_size=512,n_samples=500,num_workers=1,seed=0,learning_rate=0.0010,weight_decay=0.0000,log_every_n_steps=2,max_epochs=200 exists and is not empty.
[36m(train pid=784471)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=784471)[0m 
[36m(train pid=784471)[0m   | Name  | Type    | Params
[36m(train pid=784471)[0m ----------------------------------
[36m(train pid=784471)[0m 0 | model | GRU_RNN | 50.4 K
[36m(train pid=784471)[0m ----------------------------------
[36m(train pid=784471)[0m 50.4 K    Trainable params
[36m(train pid=784471)[0m 0         Non-trainable params
[36m(train pid=784471)[0m 50.4 K    Total params
[36m(train pid=784471)[0m 0.202     Total estimated model params size (MB)
[36m(train pid=784471)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=784471)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=784471)[0m   warnings.warn(_create_warning_msg(
2024-04-17 00:21:32,424	WARNING util.py:202 -- The `on_step_begin` operation took 0.555 s, which may be a performance bottleneck.
[36m(train pid=784471)[0m `Trainer.fit` stopped: `max_epochs=200` reached.
[36m(train pid=879061)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=879061)[0m The version_base parameter is not specified.
[36m(train pid=879061)[0m Please specify a compatability version level, or None.
[36m(train pid=879061)[0m Will assume defaults for version 1.1
[36m(train pid=879061)[0m   with hydra.initialize(
[36m(train pid=879061)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=879061)[0m The version_base parameter is not specified.
[36m(train pid=879061)[0m Please specify a compatability version level, or None.
[36m(train pid=879061)[0m Will assume defaults for version 1.1
[36m(train pid=879061)[0m   with hydra.initialize(
[36m(train pid=879061)[0m [rank: 0] Seed set to 0
[36m(train pid=879061)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=879061)[0m GPU available: True (cuda), used: True
[36m(train pid=879061)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=879061)[0m IPU available: False, using: 0 IPUs
[36m(train pid=879061)[0m HPU available: False, using: 0 HPUs
[36m(train pid=879061)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=879061)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-16_21-51-54/5_latent_size=256,batch_size=512,n_samples=500,num_workers=1,seed=0,learning_rate=0.0010,weight_decay=0.0000,log_every_n_steps=2,max_epochs=200 exists and is not empty.
[36m(train pid=879061)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=879061)[0m 
[36m(train pid=879061)[0m   | Name  | Type    | Params
[36m(train pid=879061)[0m ----------------------------------
[36m(train pid=879061)[0m 0 | model | GRU_RNN | 199 K 
[36m(train pid=879061)[0m ----------------------------------
[36m(train pid=879061)[0m 199 K     Trainable params
[36m(train pid=879061)[0m 0         Non-trainable params
[36m(train pid=879061)[0m 199 K     Total params
[36m(train pid=879061)[0m 0.797     Total estimated model params size (MB)
[36m(train pid=879061)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=879061)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=879061)[0m   warnings.warn(_create_warning_msg(
╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)       loss │
├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      198            1832.93   0.101959 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404 │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914 │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                        │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                        │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                        │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                        │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                        │
╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 2 TERMINATED | 1 RUNNING | 5 PENDING
Current time: 2024-04-16 23:27:34. Total running time: 1hr 35min 39s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00002   RUNNING                       200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00003   PENDING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0                                         │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_014ea_00002 completed after 200 iterations at 2024-04-16 23:27:34. Total running time: 1hr 35min 40s
╭────────────────────────────────────────────╮
│ Trial train_014ea_00002 result             │
├────────────────────────────────────────────┤
│ checkpoint_dir_name                        │
│ time_this_iter_s                   9.04712 │
│ time_total_s                       1851.72 │
│ training_iteration                     200 │
│ loss                               0.09343 │
╰────────────────────────────────────────────╯

Trial train_014ea_00003 started with configuration:
╭──────────────────────────────────────────╮
│ Trial train_014ea_00003 config           │
├──────────────────────────────────────────┤
│ model/latent_size                    256 │
│ params/batch_size                    512 │
│ params/n_samples                     500 │
│ params/num_workers                     1 │
│ params/seed                            0 │
│ task_wrapper/learning_rate          0.01 │
│ task_wrapper/weight_decay          1e-07 │
│ trainer/log_every_n_steps              2 │
│ trainer/max_epochs                   200 │
╰──────────────────────────────────────────╯

Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:28:04. Total running time: 1hr 36min 10s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0        1            23.7971   0.876361  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200          1846.62     0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200          1973.03     0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200          1851.72     0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:28:34. Total running time: 1hr 36min 40s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0        4            53.1747   0.864513  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200          1846.62     0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200          1973.03     0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200          1851.72     0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:29:04. Total running time: 1hr 37min 10s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0        7            82.1023   0.876141  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200          1846.62     0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200          1973.03     0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200          1851.72     0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:29:34. Total running time: 1hr 37min 40s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       10            112.485   0.809154  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:30:04. Total running time: 1hr 38min 10s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       13            141.651   0.933977  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:30:34. Total running time: 1hr 38min 40s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       16            171.718   0.961361  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:31:04. Total running time: 1hr 39min 10s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       19            200.841   0.915709  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:31:34. Total running time: 1hr 39min 40s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       22            230.191   0.944609  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:32:04. Total running time: 1hr 40min 10s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       25            260.792   0.526719  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:32:34. Total running time: 1hr 40min 40s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       28            289.961   0.479727  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:33:04. Total running time: 1hr 41min 10s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       31            319.429   0.491751  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:33:34. Total running time: 1hr 41min 40s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       34            349.537   0.861731  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:34:05. Total running time: 1hr 42min 10s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       37            379.209   0.460503  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:34:35. Total running time: 1hr 42min 40s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       40            410.169   0.653352  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:35:05. Total running time: 1hr 43min 10s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       43            439.511   0.404268  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:35:35. Total running time: 1hr 43min 40s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       46            469.176   0.370446  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:36:05. Total running time: 1hr 44min 11s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       49            498.495   0.369826  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:36:35. Total running time: 1hr 44min 41s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       52            527.379   0.560716  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:37:05. Total running time: 1hr 45min 11s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       55            558.499   0.340939  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:37:35. Total running time: 1hr 45min 41s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       58            587.518   0.407115  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:38:05. Total running time: 1hr 46min 11s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       61            616.766   0.356365  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:38:35. Total running time: 1hr 46min 41s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       64            646.584   0.430778  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:39:05. Total running time: 1hr 47min 11s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       67             676.58   0.225819  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:39:35. Total running time: 1hr 47min 41s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       71            715.863   0.229817  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:40:05. Total running time: 1hr 48min 11s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       74            744.861   0.512986  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:40:35. Total running time: 1hr 48min 41s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       77            774.278   0.306879  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:41:05. Total running time: 1hr 49min 11s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       80            803.278   0.588583  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:41:35. Total running time: 1hr 49min 41s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       83            833.221   0.241203  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:42:05. Total running time: 1hr 50min 11s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       86            862.956   0.202599  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:42:35. Total running time: 1hr 50min 41s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       89            891.939   0.297079  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:43:05. Total running time: 1hr 51min 11s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       92            922.554   0.255209  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:43:35. Total running time: 1hr 51min 41s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       95             952.01   0.307407  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:44:05. Total running time: 1hr 52min 11s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0       98            981.253   0.168815  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:44:36. Total running time: 1hr 52min 41s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      101            1010.29   0.218093  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:45:06. Total running time: 1hr 53min 11s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      104            1039.67   0.157751  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:45:36. Total running time: 1hr 53min 41s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      107            1069.01   0.169686  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:46:06. Total running time: 1hr 54min 11s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      110            1098.04   0.279031  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:46:36. Total running time: 1hr 54min 42s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      113            1128.77   0.233367  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:47:06. Total running time: 1hr 55min 12s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      116            1157.9    0.150607  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:47:36. Total running time: 1hr 55min 42s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      119            1187.13   0.401647  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:48:06. Total running time: 1hr 56min 12s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      123            1226.44   0.164444  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:48:36. Total running time: 1hr 56min 42s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      126            1256.61   0.189352  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:49:06. Total running time: 1hr 57min 12s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      129            1285.57   0.156359  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:49:36. Total running time: 1hr 57min 42s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      132            1314.45   0.146117  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:50:06. Total running time: 1hr 58min 12s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      135            1344.78   0.171234  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:50:36. Total running time: 1hr 58min 42s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      138            1374.43   0.188498  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:51:06. Total running time: 1hr 59min 12s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      141            1403.47   0.271576  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:51:36. Total running time: 1hr 59min 42s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      144            1434.38   0.184137  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:52:06. Total running time: 2hr 0min 12s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      147            1463.66   0.160994  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:52:37. Total running time: 2hr 0min 42s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      150            1493.03   0.133937  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:53:07. Total running time: 2hr 1min 12s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      153            1522.59   0.126337  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:53:37. Total running time: 2hr 1min 42s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      156            1551.84   0.212842  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:54:07. Total running time: 2hr 2min 12s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      159            1581.68   0.142587  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:54:37. Total running time: 2hr 2min 43s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      162            1610.69   0.119688  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:55:07. Total running time: 2hr 3min 13s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      165            1639.73   0.118807  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:55:37. Total running time: 2hr 3min 43s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      168            1668.73   0.127623  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:56:07. Total running time: 2hr 4min 13s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      171            1698.5    0.114681  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:56:37. Total running time: 2hr 4min 43s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      175            1737.21   0.243872  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:57:07. Total running time: 2hr 5min 13s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      178            1766.19   0.123412  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:57:37. Total running time: 2hr 5min 43s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      181            1795.13   0.128797  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:58:07. Total running time: 2hr 6min 13s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      184            1824.99   0.112171  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:58:37. Total running time: 2hr 6min 43s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      187            1854.75   0.17708   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:59:07. Total running time: 2hr 7min 13s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      190            1884.04   0.252375  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-16 23:59:37. Total running time: 2hr 7min 43s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      193            1912.9    0.237775  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-17 00:00:08. Total running time: 2hr 8min 13s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      196            1942.58   0.118883  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 3 TERMINATED | 1 RUNNING | 4 PENDING
Current time: 2024-04-17 00:00:38. Total running time: 2hr 8min 43s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00003   RUNNING                       200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      199            1971.59   0.102586  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00004   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_014ea_00003 completed after 200 iterations at 2024-04-17 00:00:59. Total running time: 2hr 9min 5s
╭────────────────────────────────────────────╮
│ Trial train_014ea_00003 result             │
├────────────────────────────────────────────┤
│ checkpoint_dir_name                        │
│ time_this_iter_s                   9.66706 │
│ time_total_s                       1981.26 │
│ training_iteration                     200 │
│ loss                               0.22695 │
╰────────────────────────────────────────────╯

Trial train_014ea_00004 started with configuration:
╭──────────────────────────────────────────╮
│ Trial train_014ea_00004 config           │
├──────────────────────────────────────────┤
│ model/latent_size                    128 │
│ params/batch_size                    512 │
│ params/n_samples                     500 │
│ params/num_workers                     1 │
│ params/seed                            0 │
│ task_wrapper/learning_rate         0.001 │
│ task_wrapper/weight_decay          1e-08 │
│ trainer/log_every_n_steps              2 │
│ trainer/max_epochs                   200 │
╰──────────────────────────────────────────╯

Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:01:08. Total running time: 2hr 9min 13s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0                                         │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:01:38. Total running time: 2hr 9min 43s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0        2            33.1187   0.877053  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200          1846.62     0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200          1973.03     0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200          1851.72     0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200          1981.26     0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:02:08. Total running time: 2hr 10min 13s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0        5            61.0529   0.872231  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200          1846.62     0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200          1973.03     0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200          1851.72     0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200          1981.26     0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:02:38. Total running time: 2hr 10min 44s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0        8            88.4254   0.859299  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200          1846.62     0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200          1973.03     0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200          1851.72     0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200          1981.26     0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:03:08. Total running time: 2hr 11min 14s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       11            115.686   0.453834  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:03:38. Total running time: 2hr 11min 44s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       15            152.028   0.58196   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:04:08. Total running time: 2hr 12min 14s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       18            179.308   0.479137  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:04:38. Total running time: 2hr 12min 44s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       21            208.525   0.446568  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:05:08. Total running time: 2hr 13min 14s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       24            235.787   0.462407  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:05:38. Total running time: 2hr 13min 44s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       28             272.06   0.42574   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:06:08. Total running time: 2hr 14min 14s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       31            299.251   0.400002  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:06:38. Total running time: 2hr 14min 44s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       34            326.462   0.481309  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:07:08. Total running time: 2hr 15min 14s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       38            362.731   0.420297  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:07:38. Total running time: 2hr 15min 44s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       41             390.9    0.546932  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:08:08. Total running time: 2hr 16min 14s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       44            418.824   0.373322  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:08:38. Total running time: 2hr 16min 44s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       47            446.127   0.422205  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:09:08. Total running time: 2hr 17min 14s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       51            483.211   0.393638  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:09:38. Total running time: 2hr 17min 44s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       54            511.976   0.408133  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:10:09. Total running time: 2hr 18min 14s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       57            539.203   0.369107  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:10:39. Total running time: 2hr 18min 44s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       60            566.863   0.367191  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:11:09. Total running time: 2hr 19min 14s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       64            603.653   0.409634  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:11:39. Total running time: 2hr 19min 45s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       67            632.707   0.436881  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:12:09. Total running time: 2hr 20min 15s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       70            660.967   0.382087  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:12:39. Total running time: 2hr 20min 45s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       73            688.586   0.365258  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:13:09. Total running time: 2hr 21min 15s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       76            716.342   0.430433  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:13:39. Total running time: 2hr 21min 45s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       80            752.754   0.402437  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:14:09. Total running time: 2hr 22min 15s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       83            780.004   0.342101  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:14:39. Total running time: 2hr 22min 45s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       86            807.307   0.355596  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:15:09. Total running time: 2hr 23min 15s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       90            844.132   0.431868  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:15:39. Total running time: 2hr 23min 45s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       93            872.216   0.376403  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:16:09. Total running time: 2hr 24min 15s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       96            899.502   0.386593  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:16:39. Total running time: 2hr 24min 45s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0       99            927.198   0.578125  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:17:09. Total running time: 2hr 25min 15s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      103            963.945   0.336721  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:17:39. Total running time: 2hr 25min 45s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      106             991.87   0.369113  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:18:09. Total running time: 2hr 26min 15s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      109            1020.41   0.333261  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:18:39. Total running time: 2hr 26min 45s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      112            1048.85   0.345279  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:19:09. Total running time: 2hr 27min 15s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      115            1077.13   0.332382  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:19:40. Total running time: 2hr 27min 45s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      119            1113.31   0.332661  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:20:10. Total running time: 2hr 28min 15s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      122            1140.54   0.33674   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:20:40. Total running time: 2hr 28min 45s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      125            1168.66   0.325168  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:21:10. Total running time: 2hr 29min 15s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      128            1196.26   0.333993  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:21:40. Total running time: 2hr 29min 45s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      132            1233.54   0.332011  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:22:10. Total running time: 2hr 30min 15s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      135            1261.43   0.318398  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:22:40. Total running time: 2hr 30min 46s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      138            1288.6    0.338145  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:23:10. Total running time: 2hr 31min 16s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      141            1316.39   0.33527   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:23:40. Total running time: 2hr 31min 46s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      145            1353.64   0.452065  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:24:10. Total running time: 2hr 32min 16s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      148            1380.86   0.319956  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:24:40. Total running time: 2hr 32min 46s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      151            1408.1    0.327425  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:25:10. Total running time: 2hr 33min 16s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      154            1436.23   0.33975   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:25:40. Total running time: 2hr 33min 46s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      158            1472.59   0.339335  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:26:10. Total running time: 2hr 34min 16s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      161            1500.3    0.315785  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:26:40. Total running time: 2hr 34min 46s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      164            1527.53   0.361881  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:27:10. Total running time: 2hr 35min 16s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      167            1557.46   0.314366  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:27:40. Total running time: 2hr 35min 46s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      171            1594.19   0.356712  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:28:10. Total running time: 2hr 36min 16s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      174            1621.33   0.363727  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:28:40. Total running time: 2hr 36min 46s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      177            1648.65   0.367214  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:29:10. Total running time: 2hr 37min 16s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      181            1685.28   0.348465  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:29:40. Total running time: 2hr 37min 46s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      184            1712.93   0.346644  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:30:10. Total running time: 2hr 38min 16s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      187            1740.11   0.35106   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:30:40. Total running time: 2hr 38min 46s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      190            1767.32   0.312826  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:31:10. Total running time: 2hr 39min 16s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      194            1805.3    0.33449   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:31:41. Total running time: 2hr 39min 46s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      197            1833.52   0.365669  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 4 TERMINATED | 1 RUNNING | 3 PENDING
Current time: 2024-04-17 00:32:11. Total running time: 2hr 40min 16s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00004   RUNNING                       200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00005   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯

Trial train_014ea_00004 completed after 200 iterations at 2024-04-17 00:32:21. Total running time: 2hr 40min 27s
╭────────────────────────────────────────────╮
│ Trial train_014ea_00004 result             │
├────────────────────────────────────────────┤
│ checkpoint_dir_name                        │
│ time_this_iter_s                   9.12208 │
│ time_total_s                       1860.82 │
│ training_iteration                     200 │
│ loss                               0.31868 │
╰────────────────────────────────────────────╯

Trial train_014ea_00005 started with configuration:
╭──────────────────────────────────────────╮
│ Trial train_014ea_00005 config           │
├──────────────────────────────────────────┤
│ model/latent_size                    256 │
│ params/batch_size                    512 │
│ params/n_samples                     500 │
│ params/num_workers                     1 │
│ params/seed                            0 │
│ task_wrapper/learning_rate         0.001 │
│ task_wrapper/weight_decay          1e-08 │
│ trainer/log_every_n_steps              2 │
│ trainer/max_epochs                   200 │
╰──────────────────────────────────────────╯

Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:32:41. Total running time: 2hr 40min 46s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0                                         │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:33:11. Total running time: 2hr 41min 16s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0        3            43.2725   0.874465  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200          1846.62     0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200          1973.03     0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200          1851.72     0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200          1981.26     0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200          1860.82     0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:33:41. Total running time: 2hr 41min 46s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0        6             72.628   0.863259  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:34:11. Total running time: 2hr 42min 16s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0        9             101.69   0.449578  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:34:41. Total running time: 2hr 42min 47s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       12            131.415   0.791541  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:35:11. Total running time: 2hr 43min 17s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       15            160.407   1.20908   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:35:41. Total running time: 2hr 43min 47s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       18            189.474   0.739094  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:36:11. Total running time: 2hr 44min 17s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       21            218.654   0.5112    │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:36:41. Total running time: 2hr 44min 47s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       24            248.404   0.601392  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:37:11. Total running time: 2hr 45min 17s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       27            277.382   0.55221   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:37:41. Total running time: 2hr 45min 47s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       30            307.928   0.43862   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:38:11. Total running time: 2hr 46min 17s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       33            336.916   0.436216  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:38:41. Total running time: 2hr 46min 47s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       36            365.897   0.408682  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:39:11. Total running time: 2hr 47min 17s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       39            396.601   0.407597  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:39:41. Total running time: 2hr 47min 47s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       42            426.378   0.386969  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:40:11. Total running time: 2hr 48min 17s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       46            465.233   0.373699  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:40:41. Total running time: 2hr 48min 47s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       49            494.262   0.387116  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:41:11. Total running time: 2hr 49min 17s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       52            523.287   0.413693  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:41:41. Total running time: 2hr 49min 47s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       55            553.786   0.39031   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:42:12. Total running time: 2hr 50min 17s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       58            582.962   0.391492  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:42:42. Total running time: 2hr 50min 47s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       61            613.454   0.405348  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:43:12. Total running time: 2hr 51min 18s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       64            642.315   0.357306  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:43:42. Total running time: 2hr 51min 48s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       67            671.318   0.735451  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:44:12. Total running time: 2hr 52min 18s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       70             700.47   0.401128  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:44:42. Total running time: 2hr 52min 48s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       73            730.701   0.383868  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:45:12. Total running time: 2hr 53min 18s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       76            759.822   0.374419  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:45:42. Total running time: 2hr 53min 48s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       79            788.751   0.331565  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:46:12. Total running time: 2hr 54min 18s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       82            818.134   0.405281  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:46:42. Total running time: 2hr 54min 48s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       85            847.857   0.455204  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:47:12. Total running time: 2hr 55min 18s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       88            876.781   0.35128   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:47:42. Total running time: 2hr 55min 48s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       92            915.877   0.454421  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:48:12. Total running time: 2hr 56min 18s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       95            944.925   0.463482  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:48:42. Total running time: 2hr 56min 48s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0       98            973.825   0.482242  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200           1846.62    0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200           1973.03    0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200           1851.72    0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200           1981.26    0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200           1860.82    0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:49:12. Total running time: 2hr 57min 18s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      101            1004.07   0.371603  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:49:42. Total running time: 2hr 57min 48s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      104            1033.85   0.332065  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:50:12. Total running time: 2hr 58min 18s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      107            1063.29   0.373117  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:50:43. Total running time: 2hr 58min 48s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      110            1092.53   0.358287  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:51:13. Total running time: 2hr 59min 18s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      113            1121.56   0.326272  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:51:43. Total running time: 2hr 59min 48s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      116            1152.59   0.316554  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:52:13. Total running time: 3hr 0min 18s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      119            1181.5    0.339381  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:52:43. Total running time: 3hr 0min 48s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      122            1210.65   0.394882  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:53:13. Total running time: 3hr 1min 19s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      125            1239.79   0.387839  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:53:43. Total running time: 3hr 1min 49s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      128            1268.93   0.371609  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:54:13. Total running time: 3hr 2min 19s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      131            1297.91   0.318456  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:54:43. Total running time: 3hr 2min 49s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      135            1336.69   0.348746  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:55:13. Total running time: 3hr 3min 19s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      138            1365.73   0.36564   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:55:43. Total running time: 3hr 3min 49s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      141            1395.19   0.379655  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:56:13. Total running time: 3hr 4min 19s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      144            1425.01   0.442811  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:56:43. Total running time: 3hr 4min 49s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      147            1454.07   0.402709  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:57:13. Total running time: 3hr 5min 19s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      150            1483.29   0.322432  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:57:43. Total running time: 3hr 5min 49s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      153            1512.4    0.474427  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:58:13. Total running time: 3hr 6min 19s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      156            1542.6    0.327695  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:58:43. Total running time: 3hr 6min 49s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      159            1572.29   0.341482  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:59:13. Total running time: 3hr 7min 19s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      162            1602.17   0.433499  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 00:59:43. Total running time: 3hr 7min 49s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      165            1631.36   0.34225   │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 01:00:14. Total running time: 3hr 8min 19s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      168            1660.33   0.321992  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 01:00:44. Total running time: 3hr 8min 49s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      171            1690.12   0.363182  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 01:01:14. Total running time: 3hr 9min 19s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
╭──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ Trial name          status         trainer/max_epochs     ...log_every_n_steps     params/batch_size     params/num_workers     params/n_samples     model/latent_size     ...pper/weight_decay     ...per/learning_rate     params/seed     iter     total time (s)        loss │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ train_014ea_00005   RUNNING                       200                        2                   512                      1                  500                   256                    1e-08                    0.001               0      174            1719.09   0.334665  │
│ train_014ea_00000   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.001               0      200            1846.62   0.313404  │
│ train_014ea_00001   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.001               0      200            1973.03   0.298914  │
│ train_014ea_00002   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-07                    0.01                0      200            1851.72   0.0934283 │
│ train_014ea_00003   TERMINATED                    200                        2                   512                      1                  500                   256                    1e-07                    0.01                0      200            1981.26   0.22695   │
│ train_014ea_00004   TERMINATED                    200                        2                   512                      1                  500                   128                    1e-08                    0.001               0      200            1860.82   0.31868   │
│ train_014ea_00006   PENDING                       200                        2                   512                      1                  500                   128                    1e-08                    0.01                0                                         │
│ train_014ea_00007   PENDING                       200                        2                   512                      1                  500                   256                    1e-08                    0.01                0                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
Trial status: 5 TERMINATED | 1 RUNNING | 2 PENDING
Current time: 2024-04-17 01:01:44. Total running time: 3hr 9min 49s
Logical resource usage: 4.0/56 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)
Current best trial: 014ea_00002 with loss=0.09342829883098602 and params={'model': {'latent_size': 128}, 'task_wrapper': {'weight_decay': 1e-07, 'learning_rate': 0.01}, 'trainer': {'max_epochs': 200, 'log_every_n_steps': 2}, 'params': {'seed': 0, 'batch_size': 512, 'num_workers': 1, 'n_samples': 500}}
[36m(train pid=879061)[0m `Trainer.fit` stopped: `max_epochs=200` reached.
[36m(train pid=973505)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=973505)[0m The version_base parameter is not specified.
[36m(train pid=973505)[0m Please specify a compatability version level, or None.
[36m(train pid=973505)[0m Will assume defaults for version 1.1
[36m(train pid=973505)[0m   with hydra.initialize(
[36m(train pid=973505)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=973505)[0m The version_base parameter is not specified.
[36m(train pid=973505)[0m Please specify a compatability version level, or None.
[36m(train pid=973505)[0m Will assume defaults for version 1.1
[36m(train pid=973505)[0m   with hydra.initialize(
[36m(train pid=973505)[0m [rank: 0] Seed set to 0
[36m(train pid=973505)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=973505)[0m GPU available: True (cuda), used: True
[36m(train pid=973505)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=973505)[0m IPU available: False, using: 0 IPUs
[36m(train pid=973505)[0m HPU available: False, using: 0 HPUs
[36m(train pid=973505)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=973505)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-16_21-51-54/6_latent_size=128,batch_size=512,n_samples=500,num_workers=1,seed=0,learning_rate=0.0100,weight_decay=0.0000,log_every_n_steps=2,max_epochs=200 exists and is not empty.
[36m(train pid=973505)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=973505)[0m 
[36m(train pid=973505)[0m   | Name  | Type    | Params
[36m(train pid=973505)[0m ----------------------------------
[36m(train pid=973505)[0m 0 | model | GRU_RNN | 50.4 K
[36m(train pid=973505)[0m ----------------------------------
[36m(train pid=973505)[0m 50.4 K    Trainable params
[36m(train pid=973505)[0m 0         Non-trainable params
[36m(train pid=973505)[0m 50.4 K    Total params
[36m(train pid=973505)[0m 0.202     Total estimated model params size (MB)
[36m(train pid=973505)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=973505)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=973505)[0m   warnings.warn(_create_warning_msg(
[36m(train pid=973505)[0m `Trainer.fit` stopped: `max_epochs=200` reached.
[36m(train pid=1067914)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=1067914)[0m The version_base parameter is not specified.
[36m(train pid=1067914)[0m Please specify a compatability version level, or None.
[36m(train pid=1067914)[0m Will assume defaults for version 1.1
[36m(train pid=1067914)[0m   with hydra.initialize(
[36m(train pid=1067914)[0m /home/ad2002/gnode/ctd/task_modeling/task_train_prep.py:46: UserWarning: 
[36m(train pid=1067914)[0m The version_base parameter is not specified.
[36m(train pid=1067914)[0m Please specify a compatability version level, or None.
[36m(train pid=1067914)[0m Will assume defaults for version 1.1
[36m(train pid=1067914)[0m   with hydra.initialize(
[36m(train pid=1067914)[0m [rank: 0] Seed set to 0
[36m(train pid=1067914)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/ray/tune/integration/pytorch_lightning.py:194: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.
[36m(train pid=1067914)[0m GPU available: True (cuda), used: True
[36m(train pid=1067914)[0m TPU available: False, using: 0 TPU cores
[36m(train pid=1067914)[0m IPU available: False, using: 0 IPUs
[36m(train pid=1067914)[0m HPU available: False, using: 0 HPUs
[36m(train pid=1067914)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:198: Experiment logs directory ./ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
[36m(train pid=1067914)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/ad2002/ray_results/train_2024-04-16_21-51-54/7_latent_size=256,batch_size=512,n_samples=500,num_workers=1,seed=0,learning_rate=0.0100,weight_decay=0.0000,log_every_n_steps=2,max_epochs=200 exists and is not empty.
[36m(train pid=1067914)[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[36m(train pid=1067914)[0m 
[36m(train pid=1067914)[0m   | Name  | Type    | Params
[36m(train pid=1067914)[0m ----------------------------------
[36m(train pid=1067914)[0m 0 | model | GRU_RNN | 199 K 
[36m(train pid=1067914)[0m ----------------------------------
[36m(train pid=1067914)[0m 199 K     Trainable params
[36m(train pid=1067914)[0m 0         Non-trainable params
[36m(train pid=1067914)[0m 199 K     Total params
[36m(train pid=1067914)[0m 0.797     Total estimated model params size (MB)
[36m(train pid=1067914)[0m SLURM auto-requeueing enabled. Setting signal handlers.
[36m(train pid=1067914)[0m /home/ad2002/.conda/envs/gnode/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
[36m(train pid=1067914)[0m   warnings.warn(_create_warning_msg(
slurmstepd: error: *** JOB 2071391 ON adroit-h11g3 CANCELLED AT 2024-04-17T01:51:45 DUE TO TIME LIMIT ***
